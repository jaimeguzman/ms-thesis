% !TeX spellcheck=es
% @Author @jaimeguzman
% Base latex template @AdinRamirez
% Repo: git@giteit.udp.cl:udp/udp-latex.git

\documentclass{udparticle}

%% DEFINITIONS
% para usarse en la escritura técnica (investigativa)
% revisar uso en el internet
\usepackage{xspace}
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\newcommand\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\newcommand\eg{\emph{e.g}\onedot} \newcommand\Eg{\emph{E.g}\onedot}
\newcommand\ie{\emph{i.e}\onedot} \newcommand\Ie{\emph{I.e}\onedot}
\newcommand\cf{\emph{cf}\onedot} \newcommand\Cf{\emph{Cf}\onedot}
\newcommand\etc{\emph{etc}\onedot} \newcommand\vs{\emph{vs}\onedot}
\newcommand\wrt{w.r.t\onedot} \newcommand\dof{d.o.f\onedot}
\newcommand\etal{\emph{et al}\onedot}
\newcommand\adhoc{\emph{ad hoc}\xspace}
\makeatother

\setlogo{EITFI}


\title{ Modelo Híbrido de LZ-78 y Machine Learning para predicción de comportamientos de usuarios basado en web access log }
\author{ Jaime Guzmán, \\ {\small mail@jguzman.cl}\protect\\[5pt]%
	{\small Adin Ramírez\thanks{Profesor guía}, y Francisco Claude \thanks{Profesor comisión}} \\
		{\small Escuela de Informática y Telecomunicaciones Universidad Diego Portales} \\
		{\small adin.ramirez@mail.udp.cl y fclaude@recoded.cl }\protect\\[5pt]% 
}


\begin{document}

\maketitle
\section{Antecedentes y Motivación}

\subsection{Contexto}

  La Web crece constantemente y por ende su infraestructura, también los tipos de usuarios y  también la concurrencia de los mismos sistemas, la cual para usuarios finales se traduce en latencia y una mejor o peor experiencia de usuario. 
  Paralelamente se suma un costo exponencial de recursos tanto en tecnologías de desarrollo como servicio que no son optimizados para poder dar una experiencia de usuario con calidad de servicio. Podemos reflexionar, entonces, que el no tener mayores recursos mejorará el rendimiento ni tampoco será lo óptimo para dar una calidad de servicio web, ya que el ancho de banda de Internet no crecerá a la misma proporción.
   
  Adicionalmente, las tecnologías para la creación de web dinámicas e asíncronas han evolucionado a favor del cliente.
  Hoy en día ya se poseen \emph{MEAN stacks} que disminuyen considerablemente la carga de un servidor, por lo cual, un buen servicio web es proveer una balanceada carga dentro del cliente y el servidor, pero cuando se poseen un volumen de datos considerables es requerido tomar decisiones que los recursos y lenguajes no cubren, es ahí el interés de hacer  web inteligente.

  Es de gran interés predecir los movimientos siguientes que un usuario tendrá en una determinada web.
  Entendiendo que la manera en que un usuario final navega es su comportamiento registrado en una web, y que se puede analizar, estudiar y registrar mediante \emph{Web Access Log} y a los cuales se puede hacer una minería de datos, Web Usage Minning. El por qué de hacer minería de datos es que cada día la web genera un innumerable cantidad de datos, por lo cual usar un algoritmo como LZ 78 presenta un interés ya que además de ser un algoritmo de compresión, este se puede usar como un algoritmo de predicción y trabajar con una mayor cantidad de datos.
  
  Los registros de acccesos de manera procesada o pre-procesada, ayudaría a ingenieros de desarrollo web y diseñadores, como a  usuarios finales a tener una experiencia de usuario mejor, disminuyendo por ejemplo la latencia en respuestas por parte de cada petición que realizan.
  
  Hoy en día, las web no pueden ser simplemente dinámicas en contenidos, debe poseer una adaptabilidad a la demanda del usuario o proveer información que permita adaptarse a los eventos, por lo tanto, es de interés el profundizar en este tópico.


\subsection{Trabajos relacionados}

% @TODO: SEGUIR TRABAJANDO EN ESTA BREVE INTRODUCCION
En este tema convergen tres áreas, por un lado existe trabajo para crear estructuras eficientes para predicciones basadas en algoritmos de compresión, como es en el caso de~\cite{Claude2014}, y, por otro lado, el uso de algoritmos de aprendizaje para realizar clustering y predecir el comportamiento basado en el mismo contenido o en la distancia del contenido que visita el usuario actual al contenido clusterizado, como es el caso de ~\cite{Poornalatha2012}, inclusive se han utilizado modelos de Markov en ~\cite{Dongshan2002}  para poder modelar el comportamiento de la web.
La tercera área son los Sistemas de Recomendación, la cual en este proyecto no se tocará pero si se mencionará el enfoque práctico que presenta área como un foco de múltiples implementaciones. 


En la literatura, el tema de la predicción en la web se ha presentado como un tema concurrente, y ha sido abarcado por varios autores. Tenemos los siguientes trabajos de interés:

\begin{enumerate}
  \item Dongshan y Junyi~\cite{Dongshan2002} destacan que un modelo de Markov puede ayudar a predecir el comportamiento de un usuario, pero con ciertas limitaciones .  Para solucionarlo presentan un nuevo modelo de Markov basado en una representación de \emph{Tree Order Model}, el cual es un híbrido entre un modelo de markov tradicional y una representación de árbol, bautizada como HTMM (por sus siglas en inglés, \emph{Hybrid-Order Tree Markov Model}).
  Su modelo fue presentado en 2002, y da una importancia a conocer la predicción de los \emph{web access}, dada la importancia de creación de redes, la minería de datos, e-commerce, y otras áreas.

  \item Domenech \etal~\cite{Domenech2006}, muestran un estudio de los rendimientos de técnicas de recuperación de datos.
  Las mismas se pueden utilizar para dar una entrada ideal a algoritmos de aprendizaje o algoritmos de predicción. 
  Los conceptos más importantes son las nuevas variables de caracterización, temporalidad, espacio y geografía, que se le suman a la predicción. 
  Además de comenzar un trabajo más elaborado de como tomar una predicción, se introducen conceptos como predicciones genéricas o específicas, variables de uso de recursos a nivel de red ó nivel procesamiento.
  Finalmente, se presenta un modelo predictivo que puede ayudar a disminuir la latencia entre la petición del cliente y la respuesta de la web, dando así un mejor rendimiento y \emph{QoS}.


  % @TODO detallar más explicarlo mas simple, darle mas enfoque al usuario segúnn del punto de vista que de los docuentos 
  % como los autores antteriores.

  \item Chen \etal~\cite{Chen2011} dan una nueva perspectiva enfocada a entregar una clara recomendación a los usuarios basada en la misma propuesta de este proyecto, los access log.
  El primer análisis realizado por los autores cubre las reglas asociativas que requiere un sistema de recomendación, pero en las pruebas propiamente tales encuentran que el análisis de los patrones detectadados dan una representación clara de como optimizar la web, y finalmente mediante sus pruebas logran una recomendación de calidad.

  \item Rajimol y Raju~\cite{Rajimol2012} minaron los patrones de los accesos web, donde el enfoque es usar los registros de acceso para crear subsecuencias y realizar comparaciones.
  La literatura presenta un interés para poder anticipar el patrón de comportamiento de la web.
  % @TODO reflexionar mas sobre este paper

  \item Kewen~\cite{kewen2012} realizó un análisis más profundo del \emph{web usage minning}.
  Parte de la importancia de este trabajo, es que después de minar los registros de accesos, logran reducir la ``\emph{bad data}''.
  %@TODO: Preguntar si este paper se escapa mucho del tema prinicipal, pero parece interesante  

  \item Poornalatha y Raghavendra~\cite{Poornalatha2012} establecen que se pueden utilizar máquinas de aprendizaje para predecir basándose en distintas entre clusters. Estos autores, al igual que Domenech \etal~\cite{Domenech2006} y Dongshan y Junyi~\cite{Dongshan2002}, comparan el objetivo de optimizar los recursos tanto en redes (disminución de latencia) y experiencia de usuario.

  \item Claude \etal~\cite{Claude2014} presentan una estructura de representación eficiente que permite dar una representación de \emph{web access log} y ofrecen las operaciones básicas de WUM.
\end{enumerate}


\subsection{Motivación}

La motivación de este proyecto de título es poder converger dos áreas de estudio para el mismo problema, predicción del comportamiento de la web. Usar recursos tanto que la industria ofrece (predicction.IO) y la academia para poder crear un algoritmo o modelo que permita dar mejor precisión.


\subsection{Descripción de la solución }

Básicamente se pretender alterar la composición del árbol generado por el algoritmo de Lempel Ziv y crear un híbrido con un Modelo de markov representado en \emph{Trie}, lo anterior no es la solución definitiva pero es la ruta que se busca estudiar.

Se utilizará como base la implementación OpenSource de Prediction.IO para poder hacer el entrenamiento de un data set provisto por el diario español \emph{Prisa}, el cual posee 1.000.000 de registros correspondientes al año 2009, septiembre.

Se medirá la precisión basado en la infraestructura de prediction.IO, con  y sin el algoritmo propuesto con el fin de encontrar un ponderado de predicciones favorables en el set de datos con el algoritmo propuesto.


\subsection{Objetivo General}
 
El objetivo general del proyecto de título es crear ó modelar un algoritmo que use LZ-78 en conjunto con una representación de un Modelo Markov y  poder encontrar predicciones basadas en patrones encontrados en \emph{access web log}, que permitan entregar información con mayor grado exactitud.
 
\subsection{Objetivo  Específicos }
 
A continuación se detallan los objetivos específicos:
 
\begin{enumerate}
  \item Estudiar y describir el estado del arte respecto a las variantes existentes de Modelos Predictivos, describiendo limitaciones pros y contras entre áreas de estudio, como futuras implementaciones y mejoras para la web.
  \item Estudio un algoritmo de compresión para usarlo como un algoritmo de predicción.
  \item Estudio un algoritmo basado en modelos de Markov que permita entregar una predicción.
  \item Implementación de algoritmo híbrido propuesto.
  \item Preparar conjuntos de datos de prueba 
  \item Ejecutar pruebas para medir, y clasificar las predicciones de rendimiento usando nuestra implementación, y comparar con algoritmos expuestos en la literatura.
  \item Analizar los resultados obtenidos y mostrar el uso del algoritmo .
\end{enumerate}


\section{Metodología de trabajo}

Se investigará en detalle el funcionamiento del algoritmo de compresión Lempel Ziv, determinando como mezclarlo o viceversa con un representación arbórea de un modelo de Markov, para luego generar una implementación del algoritmo aproximado.
Durante el desarrollo del proyecto de título, se tomarán decisiones de implementación que permitan llevar la propuesta teórica a una implementación práctica. Ya implementado el algoritmo, se realizarán pruebas en un data set anteriormente señalado.

El trabajo será guiad utilizando Gitlab de la escuela EIT y usando su sistema de issues tracking, para resolver hitos, componente y la escritura del documento de tesis. A nivel de código
e implementación se ocuparán servicios recomendados por los profesores guías y recursos disponibles por la facultad.

Estas pruebas serán luego ejecutadas en una máquina de prueba y recopilados los resultados para ser analizados.
El análisis comprenderá como se relacionan las áreas de \emph{Machine Learning} y \emph{Compresión de Algoritmos} con el fin de lograr unificar una propuesta de algoritmo. 

\section{Resultados esperados}

Se espera crear un estudio que abarque las áreas de interés y la implementación de ambas metodologías que converjan en un algoritmo, 
también la implementación que la industria del Data Science, prediction.IO, ofrece ver sus fortalezas en aspectos de predicciones y comparar con nuestra propuesta.

Además se espera entregar un listado de puntos de evaluación y mejoras propuestas para el algoritmo propuesto.

\newpage
% Preguntar a Adin que recomendaciones colocar para las fechas.
\section{Cronograma de actividades, hitos y entregables}
  \begin{center}
  \begin{tabular}{ll}
  \hline\noalign{\smallskip}
  Fecha & Actividad \\
  \hline\noalign{\smallskip}
  05/08/2015 & Presentación anteproyecto (firmado por profesor guía y comisión).\\
  07/08/2015 & Entrega resultados anteproyectos.\\
  10/08/2015 & Entrega anteproyectos corregidos.\\
  12/08/2015 & Entrega resultados correcciones.\\
  17/08/2015 & Inicio Marco de trabajo.\\
  20/08/2015 & Buscar todos los papers relacionados tanto en temas como trabajos posibles que tengan relación.\\
  24/08/2015 & Escribir estado del arte\\
  25/08/2015 & Reutilizar textos de anteproyecto para re-utilización\\
  27/08/2015 & Revisión estado del arte por profesor Guia\\
  31/08/2015 & Hacer un análisis completo de Prediction.IO y comienzo de estudio de uso.\\
  %Septiembre
  03/09/2015 & Ver como incluir el algoritmo híbrido\\
  04/09/2015 & Estructurar capítulos de tesis\\
  05/09/2015 & Proponer un introducción\\
  06/09/2015 & Recolectar datos provenientes de prisa\\
  07/09/2015 & Aprender a utilizar el algoritmo de Claude para poder dar representación \\
  10/09/2015 & Investigar representación de markov se puede implementar con el árbol del LZ78\\
  10/09/2015 & Aprender noción básica de lenguaje de programación Pascal.\\
  12/09/2015 & Levantar entorno Experimental basado en Dockers, en ambiente UDP o Propio\\
  14/09/2015 & Hacer pruebas de validación para el entorno de desarrollo y pruebas\\
  17/09/2015 & Documentación del proceso de entorno\\
  24/09/2015 & Iteración de validación con profesores Guías\\
  25/09/2015 & Redacción de capitulo "Experimental "\\
  28/09/2015 & Recolección de datos para casos sin modelo híbrido\\
  29/09/2015 & Investigación teórica de implementación\\
  
  %Octubre
  01/10/2015 & Decisión del lenguaje de implementación\\
  05/10/2015 & Codificación \\
  12/10/2015 & Iteración de Codificación y validación con profesor guía.\\
  15/10/2015 & Arreglos de algoritmo propuesto\\
  19/10/2015 & Revisión e iteración de bugs \\
  22/10/2015 & Iteración de revisión \\
  30/10/2015 & Comienzo de etapa de pruebas\\
  
  %Noviembre
  02/11/2015 & Correcciones \\
  06/11/2015 & Comienzo de etapas de pruebas con dataset\\
  09/11/2015 & Comparación con datos de literatura\\
  10/11/2015 & Escritura de capitulo\\
  12/11/2015 & Analisis de Resultados\\
  13/11/2015 & Comparativa\\
  14/11/2015 & Trabajos futuro\\
  17/11/2015 & Conclusiones\\
  23/11/2015 & Revisión de capitulo\\

  %Diciembre
  01/12/2015 & Correcciones en latex\\
  14/12/2015 & Creación de presentación\\
  14/12/2015 & Entrega Memoria Titulo I/II firmada por profesor guía.\\
  18/12/2015 & Fecha límite para que la comisión entregue correcciones.\\
  21/12/2015 & Fecha límite para que se realicen correcciones.\\

  
  \hline
  \end{tabular}
  \end{center}



  
% ------------------------- %
% \bibliographystyle{IEEEtran}
\bibliographystyle{plain}
\bibliography{anteproyecto}
 

\end{document}
