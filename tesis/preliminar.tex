\section{Contexto preliminar}\label{sec:preliminar}

	
	El contenido de \emph{Internet} crece velozmente y es necesario satisfacer cada vez a más usuarios en el menor tiempo posible. Se genera una demanda de recursos que desafía a la infraestructura de \emph{Internet}, como también a los mismos algoritmos que se usan para disponer información a usuarios con el fin de dar un buena experiencia en la navegación, por ejemplo los motores de búsqueda como \emph{Google}, \emph{Yahoo} y \emph{Bing}, intentan anticipar la búsqueda con el menor esfuerzo posible del usuario ó inclusive recomendar exactamente mientras se busca, lo cual nos da un estrecha relación con los sistemas de recomendación que están fuera de este trabajo, y también existe una competencias en entregar la mayor velocidad en los resultados, ya que un usuario que ha esperado varios segundos es posible que no vuelva a usar la misma herramienta y use la de la competencia.
	
	{El ámbito de las predicciones no solo la podemos extender a niveles de navegación de usuario, también pueden ser usadas para la detección de fraudes financieros, predicción de valores bursátiles y también para hacer diagnostico en áreas de la salud basado un conjuntos de datos genéticos o problemas de salud hereditarios. Los ejemplos anteriormente mencionados tienen una variable en común y es que las predicciones ayudan a tomar decisiones.}\label{ejemplos-casos-contextopreliminar}
	
	 Claramente existe una limitación real y física que ha sido abordada por las empresas con ofertas de computación en la nube (\emph{cloud}), ejemplo \emph{Amazon AWS, Google Cloud, Azure Microsoft, Oracle Cloud, IBM Cloud}, y es más frecuente ver que muchas compañías cuentan con su sistemas de información en estas nuevas arquitecturas. Adicionalmente, las tecnologías para la creación de web dinámica y asíncrona, entre el cliente y el servidor, han evolucionado a favor de traspasar la carga de procesamiento al cliente. Existen lenguajes y \emph{framework} que disminuyen considerablemente la carga de peticiones que se realizan a un servidor, por lo cual, un buen servicio \emph{web} provee una rápida y balanceada carga dentro del cliente y el servidor. Sobre este escenario cuando se tiene un gran volumen de datos es fundamental utilizarla para tomar decisiones. Las tecnologías actuales no cubren nativamente este problema y es ahí el interés de dar un servicio integrable para dar inteligencia a la \emph{web} como escenario de estudio.

	Podemos deducir de lo anterior que no es suficiente aumentar los recursos para obtener el mejor rendimiento, ni tampoco será óptimo ni económicamente viable, ya que el ancho de banda de \emph{Internet} no crecerá en la misma proporción que la cantidad de datos generados.

	Enfocando nuestros interés en implementar  la Ciencia de Datos Predictiva en la mejora continua de la \emph{web} y sabiendo que  actualmente esta ha evolucionado de  contenido estático a dinámico; moderado por administradores a ser  generado orgánicamente por los usuarios. Estas nuevas propiedades es una nueva evolución de \emph{Internet}. 
	
	Es necesario tener en cuenta que este trabajo no profundizará en tópicos completos de recuperación de la información (\emph{Information Retrieval}), ni en el procesamiento analítico de estos datos, pero si el estudio del aprendizaje de patrones e implementación tendrán un protagonismo en nuestra propuesta y se tendrá un completa sección de los conceptos básico~(\ref{ch:Conceptos-Basicos}) sobre \emph{Lossless Data Compression} y \emph{Machine Learning}.

	Las Máquinas de aprendizaje o \emph{Machine Learning} como se ha referido, pueden detectar patrones y aprenderlos rápidamente con un cierto algoritmo, posteriormente se puede servir sus resultados para ser analizados o procesados gracias a un modelo que en nuestro caso estudio de interés será predictivo. Nos enfocamos en la arquitectura funcional de un servidor de \emph{Machine Learning} para realizar experimentos y alterar su funcionamiento. En las etapas de un estudio usando \emph{Machine Learning} existe el entrenamiento de un set de datos, aprendizaje, etapa de servir resultados y finalmente una evaluación.  Si nos enfocamos en el aprendizaje, es requerido tener un modelo, que funcione como un algoritmo de predicción y posteriormente pueda dar una interpretación de los datos que son servidos por este modelo. Utilizaremos una arquitectura y patrón de implementación para modelos de \emph{Machine Learning} como servicio y toda la experimentación se llevará acabo ofreciendo los algoritmos y modelos como servicio basado en una Transferencia de Estado Representacional (\emph{REST}~\ref{concept-rest}), y así acércanos a la fácil implementación en áreas productivas en variadas industrias las cuales pueden presentar interés dando nuevos escenarios de estudio.

	

	Tomando la navegación de usuario como el escenario de estudio, definimos para nuestro trabajo en la manera que un usuario navega es un patrón o comportamiento registrado en \emph{webacces log}, estos se pueden analizar, estudiar y modelar con algoritmos que tengan enfoques predictivos. Estos \emph{webaccess log} se pueden usar de manera procesada o pre-procesada. Acorde a los ejemplos que hemos mencionado en esta sección~(\ref{ejemplos-casos-contextopreliminar})  y nuestro escenario de interés para predecir navegación \emph{web} de usuarios, entrega una posible ayuda a ingenieros de desarrollo web y diseñadores de experiencia de usuarios, como también en general a mejorar la experiencia del usuario, podemos mencionar que podría disminuir latencia en respuestas por parte de cada petición realizada a los servidores, con técnicas de \emph{pre-fetching predictivo} en el lado del cliente, pero para lograr esto debemos tener una registros de accesos válidos. Usar representaciones eficientes como las realizadas por Claude \etal~\cite{Claude2014} facilitaría el estudio al tener un foco en las predicciones secuenciales y no en la recuperación de estos registros. El uso de esta  minería de datos realizada en un conjunto de datos real, radica en que día a día una web genera  innumerables cantidades de información, lo que conlleva a usar algoritmos que puedan operar de manera comprimida grandes volúmenes de información o representación más liviana de datos trabajar. Es fundamental estudiar los datos que se buscan modelar y en sí trabajar con los patrones repetitivos que encontramos para poder crear un modelo predictivo, intentando de evitar un sobre-entrenamiento del modelo. Este trabajo usará los avances en \emph{Web Usage Minning} y \emph{Web Access Pattern} para buscar una nueva implementación de un modelos predictivos con  \emph{online} híbridos. Ciertamente \emph{Machine Learning} usa \emph{features}\footnote{\emph{feature:} Las característica de un \emph{Machine Learning} son propiedades individual y cuantitativas de un fenómeno que se observa dentro de un conjunto de datos.} y entre más información de entrenamiento podremos  obtener mejores predicciones. Por ejemplo la sesión de un usuario podría modelarse con gran exactitud en el mundo \emph{Machine Learning}, ya que nos entrega una gran cantidad de datos para hacer análisis predictivos. Estas sesiones comienza cuando se establece la conexión a una \emph{web}. Estableciendo dicha conexión, se crea instantáneamente una sesión de navegación automáticamente, que se almacena en el lado del cliente o que hospeda la \emph{web}. Un ejemplo de \emph{webaccess log} es lo que se observa en la Figura \ref{fig:accesslog-apache-teleton}.

\begin{figure}[tb]
	\centering
	\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
	172.31.33.116 - - [26/Nov/2015:00:12:12 +0000] "HTTP/1.1" 200 1784 "http://localhost/home" 
	"Mozilla/5.0 (Linux; Android 5.1.1; SAMSUNG SM-G920I Build/LMY47X) 
	SamsungBrowser/3.2 Chrome/38.0.2125.102 Mobile Safari/537.36"
	172.31.33.116 - - [26/Nov/2015:00:12:12 +0000] "HTTP/1.1" 200 179333 "http://localhost/news" 
	"Mozilla/5.0 (Linux; Android 5.1.1; SAMSUNG SM-G920I Build/LMY47X) 
	SamsungBrowser/3.2 Chrome/38.0.2125.102 Mobile Safari/537.36"
	172.31.33.116 - - [26/Nov/2015:00:12:12 +0000] "HTTP/1.1" 200 24660 "http://localhost/health" 
	"Mozilla/5.0 (Linux; Android 5.1.1; SAMSUNG SM-G920I Build/LMY47X) 
	SamsungBrowser/3.2 Chrome/38.0.2125.102 Mobile Safari/537.36"
	172.31.33.116 - - [26/Nov/2015:00:15:12 +0000] "HTTP/1.1" 200 24604 "http://localhost/sports" 
	"Mozilla/5.0 (Linux; Android 5.1.1; SAMSUNG SM-G920I Build/LMY47X) 
	SamsungBrowser/3.2 Chrome/38.0.2125.102 Mobile Safari/537.36"
	172.31.33.116 - - [26/Nov/2015:00:20:12 +0000] "HTTP/1.1" 200 4860 "http://localhost/home" 
	"Mozilla/5.0 (Linux; Android 5.1.1; SAMSUNG SM-G920I Build/LMY47X) 
	SamsungBrowser/3.2 Chrome/38.0.2125.102 Mobile Safari/537.36"
	172.31.33.116 - - [26/Nov/2015:00:22:19 +0000] "HTTP/1.1" 200 4841 "http://localhost/finances" 
	\end{lstlisting}
	
	
	
	\caption{Ejemplo de un \emph{webaccess Log} de un servidor Apache.}
	\label{fig:accesslog-apache-teleton}
\end{figure}


  En la Figura \ref{fig:accesslog-apache-teleton}, existe mucha información interesante como la \texttt{IP} desde donde se conecta, el tipo de navegador, el dispositivo desde donde se conecta, si es un teléfono inteligente o un navegador de escritorio, la fecha en que se realizó el acceso y también lo más relevante el destino del usuario. Anteriormente mencionamos la importancia para nuestro trabajo tener un versión simplificada de la sesión. Al tener un simplificada la representación podemos usar mas datos y generar un modelo de datos para predecir, en este instante se comprenderá la importancia de el uso de un algoritmo de compresión de tipo \emph{Lossless Data Compression}, el cual nos permitirá crear modelos que sean creados con mayor volumen de datos que las técnicas tradicionales de \emph{Machine Learning} y además usando propiedades de la compresión y la \emph{Teoría de la Información}, que nos entreguen resultados interesantes dado nuestro escenario de modelo predicción de navegación discreta de usuarios en una \emph{web}.
   
  Esta nueva perspectiva posee una adaptabilidad a la demanda o proveer información que permita adaptarse a los eventos, por lo tanto, presenta una gran ayuda para conocer futuros eventos y ayudar a tomar decisiones, por ejemplo el siguiente acceso, basado en un mayor cantidad de datos históricos. Sobre esta idea se pueden hacer integraciones en áreas \emph{Lossless Data Compression} y \emph{Machine Learning} siendo un gran desafío. Independientemente del área, el problema común  se puede resolver de manera acotada en cada área, pero se busca encontrar las propiedades en común y usarlas para lograr un resultado predictivo en demanda.  