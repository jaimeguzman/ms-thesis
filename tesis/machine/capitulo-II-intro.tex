
\chapter[Machine Learning y Lossless Data Compression]{Machine Learning y Lossless Data Compression}\label{ch:Compresion-Machine-Learning}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Que busco inducir de machine learnig
% Que buscon inducir de LDC
% Como los cruzo
% Donde el lector puede ir buscando lo que necesita para comprender
% Una idea donde se junta la prediccion con la prediccion son los VMM

%%%%% SECCION DE MACHINE LEARNIGN PARA ANALISIS DE DATOS SECUENCIALES

Una de las áreas que comprende la Inteligencia Artificial es \machinelearning, en esta área de conocimiento existen algoritmos, técnicas y metodología que permiten realizar un entrenamiento a un sistema, con el fin de aprender desde un conjunto de datos. En los últimos años esta área ha tenido mayor atención, debido a la gran cantidad de datos que están disponibles y el mayor interés por encontrar información relevante dentro de estos datos. Anteriormente existían limitación de recursos, que en la actualidad el \cloudcomputing logra solucionar, de tal manera que se abren instancias para nuevas investigaciones y desarrollos. Adicionalmente al tener mejor infraestructura para funcionar, existe una gran demanda de soluciones a problemas y necesidades que la industria presenta. Esto produce  a que exista una constante competencia en la extracción de conocimiento, desde conjuntos de datos no procesados.

El conocimiento en este contexto, es a menudo definido como un modelo que puede ser actualizado o ajustado constantemente, a medida que nuevos datos se van generando. Los modelos nacen para satisfacer cierto dominio específico de determinados problemas, por ejemplo la evaluación del riesgo de créditos financieros, reconocimiento de rostros o patrones visuales, maximizar la calidad del servicio, clasificación de los síntomas patológicos para ciertas enfermedades, optimización de redes informáticas, detección de intrusiones en escenarios de seguridad informática y también se pueden analizar el comportamiento en línea de los usuarios e historial de compras ó navegación  de un cierta \web. Específicamente, un algoritmo de \machinelearning ``infiere patrones y asociaciones entre distintas variables, y conjunto de datos''~\cite[capítulo 8]{guller2015big}, en otras palabras, un algoritmo de \machinelearning aprende para predecir. 


Un modelo es una construcción matemática para capturar patrones de un conjunto de datos. Como señala \emph{Guller}~\MLGuller, básicamente es una función que toma ciertas características de un conjunto de datos, como sus valores iniciales y sus resultados.  Los modelos son las piezas fundamentales de cualquier implementación de \machinelearning, describen los datos observados de un sistema, en muchos casos, estos modelos se aplican a nuevos conjuntos de datos que ayudan a un nuevo modelo lograr aprender nuevos comportamientos y también predecirlos~\MLPDASunila. Se clasifican de la siguiente manera:

\begin{itemize}
\menorEspacioItemize		
 \item Modelos Lógicos
 \item Modelos Geométricos
 \item Modelos Probabilísticos
\end{itemize} 
%La aplicación de algún modelos debe ser definida por un caminio para lograr un objetivo, como el nuestro que es el de lograr predicciones con datos secuenciales. 

Cada uno de los modelos señalados son entrenados por algoritmos de \machinelearning, nos concentraremos en los modelos probabilísticos, los cuales pueden ser entrenados por algoritmos de \emph{regresión lineal}, \emph{forecasting} o \emph{predicción}. Todos los algoritmos mencionados anteriormente intentan de alguna manera determinar que pasará en el futuro, dado a cierta información provista de experiencia o conocimiento previo.

Esta sección entrega un punto introductorio a ciertos fundamentos y referencias de algoritmos que son mencionados. Estos se agrupan en la siguientes categorías:

\begin{itemize}
	\menorEspacioItemize
	\item \textbf{Regresión}
			\input{machine/regresion}
	\item \textbf{Clasificadores}	
			\input{machine/clasificadores}
	\item \textbf{Predictores}
			\input{machine/predictores}
	% \item[Optimización]	
	% 	\input{machine/optimizacion}
\end{itemize}
 
\uncm


Existen varios algoritmos con distintos estos fines, los anteriores no son la totalidad que ofrece el área de  \machinelearning. Todos los algoritmos pueden ir sufriendo variaciones o alteraciones acorde a como se presenten los datos. Estos deben conocerse para que en el proceso de entrenamiento del  modelo o el uso de estos sea válido. Es lógico pensar que si usa un algoritmo para un escenario que no corresponde este retorne resultado inconsistente, por ende, es importante conocer el dominio y seleccionar correctamente el algoritmo que se utilizará.


Al momento de realizar nuevos algoritmos o modificaciones que ayudan a algunos modelos tradicionales de \machinelearning, se abre un nueva perspectiva para abordar mas problemas con nuevos propósitos. \emph{Sculley y Brodley} en~\cite{Sculley2006} plantean y discuten esta nueva perspectiva con un enfoque más teórico e empírico. La idea fundamental que plantean es que si se tiene un \emph{string} $x$ e $y$, y  se comprimen juntos estos pueden ser más eficientes, es decir,  ambos \emph{strings} comparten la misma información. El caso anterior es la perspectiva de juntar las áreas de \machinelearning y \emph{Data Compression}. 

Si estos \emph{strings} representan grandes volúmenes de datos o largas secuencias de símbolos, usando algunas técnicas o algoritmos de compresión, pueden ayudar considerablemente a enfrentar este escenario, en el cual existe gran complejidad al momento de realizar el entrenamiento. Además, si se consideran estas aproximación, es posible entregar mejores resultado, siendo un beneficio considerable. En el ejemplo anterior como en otras tareas de \machinelearning se puede usar algoritmos de compresión, tanto en tareas tradicionales de clasificación ó agrupamiento.  Esta perspectiva inclusivas no son novedosas y ha aparecido en variados campos de interés~\cite{Sculley2006}, algunas veces con la promesa de reducir los problemas, por ejemplo cuando se realiza la selección implícita de ciertas características de un conjunto de datos. 

Li~\etal~\cite{Li2005}, lograron implementar una nueva clase de \emph{string kernel}\footnote{Los String kernel, son operaciones que permiten trabajar funciones no lineales, como lineales. Para un explicación detallada ver~\cite{Li2005}.} basada en un algoritmo de compresión y lo utilizaron para manejar un clasificador \texttt{SVM} para la clasificación de géneros musicales. Uno de los algoritmos utilizado por \emph{Sculley}~\cite{Sculley2006}, para evaluar este espacio vectorial común, es de la familia de \emph{Lempel-Ziv}, más adelante se detallará en la  sección~\ref{ch2:sec-lzfamily}.
% AGREGAR EL EJEMPLO DE DETECCION DE SPAM TROLES

Como se ha señalado, una de las motivaciones que se puede tener al usar técnicas de compresión es ahorrar espacio para ciertos conjuntos de datos que se desean entrenar. Por otro lado también se puede ahorrar tiempo en transmitir o mover ciertos conjuntos de datos, lo que implica que finalmente en la mayoría de los datos se elimina la redundancia de información innecesaria.

Los algoritmos de compresión pueden ser con o sin pérdida de informacion, abordaremos solamente los algoritmo sin pérdida (\losslessdatacompression). Estos algoritmos en función de los análisis predictivo sobre secuencias han sido adaptados como \lzSieteOcho~\cite{ZivLempel1978} y Active Lezi\cite{Gopalratnam2007}. Por otra parte, ciertos algoritmos de \machinelearning, tales como redes neuronales y \emph{sequential rule mining} se han aplicado para realizar predicciones de secuencias~\cite{Gueniche2015}.

\emph{Begleiter}~\etal en~\cite{Begleiter2004} señalan que existe una  íntima relación entre predicciones  en secuencias discretas y \losslessdatacompression, donde, en principio cualquier algoritmo de compresión sin pérdida puede ser utilizado para realizar predicciones y viceversa (ver \emph{Feder y Merhav} en~\cite{Feder1992}).

También existen algoritmos que son \emph{modelos variables de markov}, estos modelos están basados en Markov. Se detallará más en la sección~\ref{sec-clas-alg-compreessdata}, además se realizará una aproximación a los \emph{modelos ocultos de markov}~\ref{ch2:sec-hmm} que son más asociados a aproximaciones con \machinelearning.




\uncm
Hemos introducidos varios conceptos que veremos más adelante, uno de los más importante es el acercamiento de dos areas para poder complementar una problemática específica y común. Hemos hablado de como ciertos modelosm, y como son entrenados por algoritmos. Además hemos visto una primera revisión a la literatura en la cual ha validado a que podemos hacer esta intersección de áreas de conocimiento de manera correcta, para lograr el objetivo de esta tesis, que es las predicciones. En las proximas secciones de este capítulo se estudiará un base teórica para comprender el aporte que puede hacer un algoritmo \losslessdatacompression para un sistema de entrenamiento y predicción de \machinelearning.


% Summary

% In this chapter, you learned about different regression, classification, and clustering algorithms. You learned how each of the algorithms work, and the type of problems for which they are suited. The goal of this chapter is to provide you with the foundation for using these algorithms to solve the various problems covered in upcoming chapters. In addition, the resources provided in this chapter will help you learn more deeply about state-of-art machine learning and the theory behind some of these algorithms.





