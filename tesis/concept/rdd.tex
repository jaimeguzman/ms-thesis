Los \emph{Resilient Distributed Datasets} (\texttt{RDD}) permiten que un servidor o arquitectura de servidores de \emph{Machine Learning} puedan mantener los datos de un modelo de predicción, fuente de datos o valores de evaluación persistente sin importar en el flujo que sea invocado, esto es muy útil cuando se realizan procesamineto en \emph{clusters} y los datos se encuentran transversalmente sin tener pérdida procesamiento ni ejecución.

Esta colección es fundamental para \emph{PredictionIO} y \emph{Apache Spark}, que se verán en el Capitulo~\ref{ch:experimetal-all}. Esta estructura distribuida de almacenamiento de objetos inmutables separa los conjuntos de datos en un \texttt{RDD}\cite{zaharia2010}, que  es divido en particiones lógicas, las cuales puedes ser computadas en distintos cluster. Los \texttt{RDD} pueden contener cualquier tipo de objeto de los siguientes lenguajes: \emph{Python}, \emph{Scala} y \emph{Java}, incluyendo clases definidas por el usuario. 

Formalmente los \texttt{RDD} son solo de lectura como colecciones de objetos distribuidas. Pueden ser creados a través de  operaciones deterministas en una cierta tabla o un almacenamiento externo u otra \texttt{RDD}.
Otra de las características es que son colecciones tolerantes a fallas que pueden operar individualmente o en paralelo.
\emph{Apache Spark}\footnote{Apache Spark, \url{http://spark.apache.org}} hace el uso del concepto de \texttt{RDD} para lograr rapidez y eficiencia en las operaciones de \emph{MapReduce}, si es requerido. Destacamos la escabilidad de esta librería para un gran nivel de cómputo, pero en este trabajo no se explicará el fundamento de \emph{Apache Spark}, pero si se utilizarán algunos conceptos como \texttt{RDD} mediante el entorno de trabajo de \emph{PredictionIO}.
