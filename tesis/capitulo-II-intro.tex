

\chapter[Machine Learning y Lossless Data Compression]{Machine Learning y Lossless Data Compression}\label{ch:Compresion-Machine-Learning}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Que busco inducir de machine learnig
% Que buscon inducir de LDC
% Como los cruzo
% Donde el lector puede ir buscando lo que necesita para comprender
% Una idea donde se junta la prediccion con la prediccion son los VMM

%%%%% SECCION DE MACHINE LEARNIGN PARA ANALISIS DE DATOS SECUENCIALES

Una de las áreas que comprende la Inteligencia Artificial es \machinelearning, esta permite realizar entrenamientos a un sistema para aprender desde un conjunto de datos. Este tema ha tenido atención durante los últimos años, dado a las mejoras en disponibilidad de recursos que el \cloudcomputing ofrece para nuevas investigaciones y desarrollo, también existe un gran demanda de soluciones a problemas y una necesidad competitiva de extracción de conocimiento de ciertos conjunto de datos.

El conocimiento es a menudo definido como un modelo que puede ser actualizado o ajustado constantemente a medida que nuevos datos se van generando y usando. Los modelos son  de dominio específico que van por ejemplo desde la evaluación del riesgo de crédito financieros, reconocimiento de rostros, maximizar la calidad del servicio, la clasificación de los síntomas patológicos de ciertas enfermedades, optimización de redes informáticas, detección de intrusiones de seguridad y también se pueden analizar el comportamiento en línea de los usuarios e historial de compras ó navegación  de un cierta \webs. Específicamente, un algoritmo de \machinelearning ``infiere patrones y asociaciones entre distintas variables y conjunto de datos''~\cite[capítulo 8]{guller2015big}, en otras palabras un algoritmo de \machinelearning aprende para predecir. 


Un modelo es una construcción matemática para capturar patrones de un conjunto de datos. Como señala \emph{Guller}~\MLGuller, básicamente un modelo es una función que toma ciertas características de un conjunto de datos como sus valores iniciales y resultados.  Estos son la pieza fundamental de cualquier implementación de \machinelearning, describen lo datos observados de un sistema. En muchos casos estos modelos se aplican a nuevos conjuntos de datos  que ayudan a un modelo aprender nuevos comportamientos y también predecirlos~\MLPDASunila. Se clasifican de la siguiente manera:

\begin{itemize}
 \item Modelos Lógicos
 \item Modelos Geométricos
 \item Modelos Probabilisticos
\end{itemize} 


Cada uno de estos modelos son entrenados por algoritmos de \machinelearning, nos concentraremos en los modelos probabilísticos estos pueden ser entrenados por algoritmos de \emph{regresión lineal}, \emph{forecasting} o \emph{predicción}. Todos los algoritmos mencionados anteriormente intentan de alguna manera determinar que pasará en el futuro, dado a la información provista de experiencia o conocimiento previo.


%La aplicación de algún modelos debe ser definida por un caminio para lograr un objetivo, como el nuestro que es el de lograr predicciones con datos secuenciales.  



Esta sección entrega un base a ciertos fundamentos y referencias de algoritmos que son mencionados y refereidos. Se agrupa los algoritmos en  las siguientes categorías:

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\item Regresión
	\item Clasificadores	
	\item Predictores
	% \item[Optimización]	
	% 	\input{machine/optimizacion}
\end{itemize}



\subsubsection{Regresión}
		\input{machine/regresion}
\subsubsection{Clasificadores}
		\input{machine/clasificadores}
\subsubsection{Predictores}
		\input{machine/predictores}

\vspace{1cm}

Existen una gran cantidad de algoritmos, los anteriores no son la totalidad que ofrece \machinelearning, todos los modelos pueden ir sufriendo variaciones o alteraciones acorde a como se presenten los datos. Estos deben conocerse para que el modelo o el uso de estos sea valido, es lógico pensar que si usa un algoritmo para un escenario que no corresponde este sea totalmente invalido o inconsistente.



Al momento de realizar nuevos algoritmos o modificaciones que ayuden a modelos tradicionales de \machinelearning, se crear un nueva perspectiva para abordar variados problemas. \emph{Sculley y Brodley} en~\cite{Sculley2006} plantean y discuten estas perspectiva con un enfoque más teórico e empírico, la idea fundamental que planten es que si se tiene un \emph{string} $x$ e $y$ y al ser comprimidos juntos son eficaces, ambos \emph{string} comparten la misma información. Si estos \emph{string} representarán grandes volúmenes de datos puede ser un escenario el cual puede sumar complejidad al momento de realizar un entrenamiento, sin usar técnicas de compresión, pero si se considera esta aproximación es posible entregar mejores resultado, siendo un beneficio a favor. En el ejemplo anterior como en otras tareas se puede usar algoritmos de compresión sobre \machinelearning, tanto en tareas tradicionales de clasificación y agrupamiento.  Esta perspectiva no es nuevo y ha aparecido en variados campos~\cite{Sculley2006}, algunas veces con la promesa de reducir los problemas en la selección implícita de ciertas características de un conjunto de datos. 

Li~\etal en~\cite{Li2005} lograron implementar una nueva clase \emph{string kernel}\footnote{Los String kernel, son operaciones que permiten trabajar funciones no lineales, como lineales. Para un explicación detallada ver~\cite{Li2005}.} basada en un algoritmo de compresión y lo utilizaron para manejar un clasificador \texttt{SVM} para la clasificación de géneros musicales. El algoritmo utilizado por \cite{Sculley2006} es de la familia de {Lempel and Ziv}, el cual lo veremos mas adelante en la sección ~\ref{}.


Una de las motivaciones que se puede tener al usar compresión es ahorrar espacio para ciertos conjuntos de datos que se desean entrenar, también ahorrar tiempo en transmitir o mover cierto conjunto de datos y finalmente la mayoria de los datos en general presentantan redundancia de información.

Los algoritmos de compresión pueden ser con o sin pérdida de informacion, abordaremos solamente los algoritmo sin pérdida (\losslessdatacompression), estos en función de los análisis predictivo no presente explícitamente una acercamiento, pero poseen una estrecha relación,temáticas que usan ciertos algoritmos de tipo probabilistas de \machinelearning. Estos algoritmos son los \emph{modelos variables de markov}, son tipos de modelos los cuales están basados en las cadenas de Markov, esto se detallará con mayor precisión en la sección~\ref{}, además se realizará una aproximación a los \emph{modelos ocultos de markov} que son mas asociados a estudios de \machinelearning.





\subsubsection{Resumen}

En esta introducción hemos introducidos varios conceptos que veremos mas adelante, uno de los más importante es el acercamiento de dos areas para poder complementar una solución específica. Hemos hablado de como ciertos modelos son entrenados por algoritmos. Además hemos visto una primera revisión a la literatura en la cual ha validado a que podemos hacer esta intersección de áreas de manera correcta, para lograr un objetivo como es las predicciones. En las proximas secciones de este capitulo se entregará una base mas detallada para comprender el aporte de que puede hacer un algoritmo \losslessdatacompression para un modelo de entrenamiento y predicción de \machinelearning.


% Summary

% In this chapter, you learned about different regression, classification, and clustering algorithms. You learned how each of the algorithms work, and the type of problems for which they are suited. The goal of this chapter is to provide you with the foundation for using these algorithms to solve the various problems covered in upcoming chapters. In addition, the resources provided in this chapter will help you learn more deeply about state-of-art machine learning and the theory behind some of these algorithms.





