


El algoritmo de Predicción por coincidencia parcial~\PPM~(por sus siglas en inglés \emph{Prediction by Partial Match})~\cite{Shkarin2002 }, es considerado uno de los mejores algoritmos del tipo \losslessdatacompression. El algoritmo requiere un tope superior $D$ en el orden máximo  de un modelo variable de Markov (\emph{\texttt{VMM}}) para construirse. \PPM maneja el problema de frecuencia cero~\cite{Begleiter2004} usando dos mecanismo llamados:
	\begin{itemize}
		\menorEspacioItemize
		\item Escape
		\item Exclusion
	\end{itemize}
	
Para un método que considera diferentes órdenes de modelos, retomamos una vez más a la compresión de datos y la familia de predictores.  Esto ha sido usado con gran efecto, para un marco predictivo basado en \lzSieteOcho. 

Algoritmos  \PPM consideran modelos de Markov de diferente orden,  con el fin de construir una distribución de probabilidad mediante la ponderación de modelos de diferente orden. En nuestro escenario predictivo, \emph{Active LeZi} construye un orden-k del modelo de Markov. Ahora empleamos la estrategia \PPM de exclusión para reunir información de los modelos de orden 1 a $k$ para asignar el siguiente símbolo de su valor de probabilidad. Este método se ilustra considerando la secuencia de ejemplo utilizado en los apartados anteriores: \texttt{aaababbbbbaabccddcbaaaa}.

% FATLA una CITA a ACTILEZI
La ventana mantenida por \emph{Active Lezi}~\cite{Gopalratnam2007} representa el conjunto de contextos utilizado para calcular la probabilidad  del siguiente símbolo. En nuestro ejemplo, el último se utiliza la frase \texttt{aaa}. Dentro de esta frase, los contextos que pueden ser utilizados son todos sufijos dentro de la frase, excepto la ventana en sí (es decir, \texttt{aa} , \texttt{a}, y el contexto nulo).

	
% @TODO: Trabajar mas en este tema. y mencionar mas adelante porque usar LZ y no este, rendimiento