%%%%%%%  
%%%%%%%  
%%%%%%%  

Los Modelos ocultos de Markov o en sus siglas en inglés \HMM (\emph{Hidden Markov Model})  básicamente son un modelo probabilistico basado en los procesos de Markov, también conocido como cadenas de Markov. Una cadena o proceso de Markov es una secuencia de eventos, estos se pueden representar por estados, la probabilidad de cada uno estados sólo depende del estado anterior.


Estos \HMM son modelos dinámicos con un proceso estocástico doble, en el cual el sistema es modelado mediante un proceso de markov con estados no observados directamente, es decir, estados escondidos. Aunque el proceso estocástico es subyacente y no directamente observable, este se puede observar sobre otro conjunto de procesos estocásticos, que producen una secuencia de simbolos observados. Normalmente han sido usados en reconocimiento de voz o habla, reconocimiento de patrones de imágenes ó video, traducción de textos, clasificación de texto, etiquetado de documentos y finalmente también en compresión de datos.

En los modelos tradicionales de Markov, los estados son visibles para el observador, y los estados de transición son visibles a un observador, y los estados de transición son parametizables, usando probabilidades transición. Cada estado tiene una distribución de probabilidad sobre la salida \emph{emitida} (variables observadas).
% Y QUE PASA CON LOS HMM se habla de los tradicionales falta mejorar esta idea




% \subsubsection{Terminología para HMM}


Para poder predecir la sequencia de estado más probable, los \HMM hacen un sistema de observación y transmisión. Una gran diferencia de los modelos ocultos de markov y un proceso de markov clásico es que en los primeros, los estados no son observables.  Una nueva observación se emite con una probabilidad conocida como la probabilidad de emisión cada vez que el estado del sistema o modelo cambios. 

\subsubsection{Fuentes de aleatoriedad para HMM}

Los estados en \HMM son modelos generativos, los cuales modelan la distribución conjunta de  observaciones y estados ocultos.

\begin{itemize}
	\menorEspacioItemize
	\item Transición entre estados.
	\item La emisión de una observación cuando se da un estado.
\end{itemize}


\subsubsection{Escenario formal HMM}

\begin{itemize}
	\menorEspacioItemize
	\item Un conjunto de observaciones
	\item Una secuencia de estados ocultos
	\item Un modelo que maximiza la probabilidad conjunta de las observaciones y estados ocultos, conocido como el modelo Lambda.
\end{itemize}


Un modelo Lambda,$\lambda$, está compuesto de probabilidades $\pi$ iniciales, las probabilidades de las transiciones de estado según la definición de la matriz A, y las probabilidades de los estados que emiten una o más observaciones.







%@TODO: Definir una notación matematica para empezar hablar de HMM


 


Si resumieramos los problemas fundamentales que pueden ser trabajados por \HMM, tendríamos los tres problemas siguientes:

\begin{enumerate}
	\menorEspacioItemize
	\item Evaluación de un modelo: Evaluar la probabilidad de una secuencia de observaciones para un \HMM dada  $(M = (A, B, M)).$
	\item Decodificar la ruta:  EVALUAR la secuencia óptima de un modelo de estados $Q$ (Estados ocultos) para una determinada secuencia de observaciones y un modelo \HMM $M = (A, B, M).$
	\item  Entrenamiento del modelo:   determinar el conjunto de parámetros del modelo que explica mejor la señal observada.

\end{enumerate}









 












%\vspace{1cm}

%\input{sec-algo-viterbi}

