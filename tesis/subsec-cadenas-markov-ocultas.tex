%%%%%%%  


% MODEL LEARNING:
% GIVEN THE DATA, TO LEARN A PROBABILISTIC MODEL WITH OPTIMIZED STRUCTURES AND PARAMETERS.





% THE THREE FUNDAMENTAL PROBLEMS ADDRESSED BY HMMS CAN BE SUMMARIZED AS FOLLOWS:

% MODEL EVALUATION: EVALUATE THE LIKELIHOOD OF A SEQUENCE OF OBSERVATIONS FOR A GIVEN HMM (M = (A,B,Π)).
% PATH DECODING: EVALUATE THE OPTIMAL SEQUENCE OF MODEL STATES (Q) (HIDDEN STATES) FOR A GIVEN SEQUENCE OF OBSERVATIONS AND HMM MODEL M = (A,B,Π).
% MODEL TRAINING: DETERMINE THE SET OF MODEL PARAMETERS THAT BEST ACCOUNTS FOR THE OBSERVED SIGNAL.

% THE FUNDAMENTAL THEORY OF HMMS WAS DEVELOPED ON THE BASIS OF PIONEERING WORK BY BAUM AND COLLEAGUES (BAUM AND PETRIE 1966; BAUM AND EAGON 1967; BAUM AND SELL 1968; BAUM ET AL. 1970; BAUM 1972). EARLIER WORK IN THIS AREA IS CREDITED TO STRATONOVICH (1960), WHO PROPOSED AN OPTIMAL NONLINEAR FILTERING MODEL, BASED ON THE THEORY OF CONDITIONAL MARKOV PROCESSES. A RECENT CONTRIBUTION TO THE APPLICATION OF HMM WAS MADE BY RABINER (1989), IN THE FORMULATION OF A STATISTICAL METHOD OF REPRESENTING SPEECH. THE AUTHOR ESTABLISHED A SUCCESSFUL IMPLEMENTATION OF AN HMM SYSTEM, BASED ON DISCRETE OR CONTINUOUS DENSITY PARAMETER DISTRIBUTIONS.




Los \emph{HMM} o cadenas de Markov ocultas, son un modelo estadístivo en cual un sistema es modelado como un proceso de Markov con parámetros desconocidos.

Las cadenas ocultas de Markov o en sus siglas en inglés HMM (Hidden Markov Model) es básicamente un modelo probabilistico basado en los procesos de Markov, también conocido como cadenas de Markov. 

Podemos señalar que los \emph{HMM} son un proceso estocástico doble, en el cual el sistema es modelado con un proceso de markov con estados no observados, estados escondidos. Aunque el proceso estocástico es subyacente
y no directamente observable, este se puede observar sobre otro conjunto de procesos estocásticos, que producen una secuencia de simbolos observados.

En los modelos tradicionales de Markov, los estados son visibles para el observador, y los estados de transición son visibles a un observador, y los estados de transición son parametizables, usando probabilidades transición.
Cada estado tiene una distribución de probabilidad sobre la salida \emph{emitida} (variables observadas).

Para poder predecir la sequencia de estado más probable, los \emph{HMM} hacen un sistema de observación y transmisión.

 % THE STATES OF THE HMM CAN ONLY BE INFERRED FROM THE OBSERVED EMISSIONS—HENCE, THE USE OF THE TERM HIDDEN. THE SEQUENCE OF OUTPUT EMISSIONS GENERATED BY AN HMM IS USED TO ESTIMATE THE SEQUENCE OF STATES. HMMS ARE GENERATIVE MODELS, IN WHICH THE JOINT DISTRIBUTION OF OBSERVATIONS AND HIDDEN STATES IS MODELED.







Normalmente han sido usados en reconocimiento de voz o habla, reconocimiento de patrones de imágenes ó video, traducción de textos, clasificación de texto, etiquetado de documentos y finalmente también en compresión de datos.

% repetido
Una gran diferencia de los modelos ocultos de markov y un proceso de markov clásico es que en los primeros, los estados no son observables.  Una nueva observación se emite con una probabilidad conocida como la probabilidad de emisión cada vez que el estado del sistema o modelo cambios.

En la actualidad hay dos fuentes de aleatoriedad:

\begin{itemize}
	\item Transición entre estados
	\item La emisión de una observación cuando se da un estado
\end{itemize}

%Vamos a volver a utilizar el ejemplo cajas y pelotas. Si las cajas son estados ocultos (no observable), entonces el usuario dibuja las bolas cuyo color no es visible. La probabilidad de emisión es la probabilidad de bik = p (ot = colork | qt = Si) para recuperar una bola de color k de una caja oculta I, como se describe en el siguiente diagrama:



\textbf{Nota: Invariancia del tiempo}

Los \textit{HMM} requieren que los elementos de transición, $a_{ji}$, son independientes en el tiempo. Esta propiedad se conoce como restricción estacionaria u homogénea.

\textbf{Nota: Normalizacion}

Los estados de entrada y los datos de observaciones pueden tener que ser normalizados y se convierten en probabilidades antes de inicializar las matrices A y B.

Input states and observations data may have to be normalized and converted to probabilities before initializing the matrices A and B.




Para formalizar un escenario de HMM:

\begin{itemize}
	\item Un conjunto de observaciones
	\item Una secuencia de estados ocultos
	\item Un modelo que maximiza la probabilidad conjunta de las observaciones y estados ocultos, conocido como el modelo Lambda.

\end{itemize}


Un modelo Lambda,$\lambda$, está compuesto de probabilidades $\pi$ iniciales, las probabilidades de las transiciones de estado según la definición de la matriz A, y las probabilidades de los estados que emiten una o más observaciones.



%@TODO: Definir una notación matematica para empezar hablar de HMM

% HMM execution state
% The canonical forms of the HMM are implemented through dynamic programming techniques. These techniques rely on variables that define the state of the execution of the HMM for any of the canonical forms:

% Alpha (the forward variable): The probability of observing the first t < T observations for a specific state at Si for the observation t, αt(i) = p(O0:t, qt=Si|λ)

% Beta (the backward variable): The probability of observing the remainder of the sequence qt for a specific state βt(i) = p(Ot+1:T-1|qt=Si,λ)

% Gamma: The probability of being in a specific state given a sequence of observations and a model γt(i) =p(qt=Si|O0:T-1, λ)

% Delta: The sequence to have the highest probability path for the first i observations defined for a specific test δt(i)

% Qstar: The optimum sequence q* of states Q0:T-1
% DiGamma: The probability of being in a specific state at t and another defined state at t+1 given the sequence of observations and the model γt(i,j) =p(qt=Si,qt+1=Sj|O0:T-1, λ)

% Each of the parameters is described in the section related to each canonical form. Let's create a class HMMState that encapsulates the variables used in the implementation of the three canonical cases.


%%%%%%%%% -> Realmente no se sis es necesarios definir los estados de ejecución de HMM




\vspace{1cm}


\textbf{Algoritmo Viterbi}

La extración del mejor estado de la secuencia (La secuencia de estado que posee la mayor probabilidad) toma mucho tiempo. Un alternativa es usar técnicas de programación dinámica para encontrar la mejor secuencia %qt
a través de la iteración. Este algoritmo es conocido como \emph{Viterbi}. 

Dada una secuencia de estados $q_{t}$ y una secuencia de observación  $o_{j}$, la probabilidad $\gamma_{t}(i)$ 
%for any sequence to have the highest probability path for the first T observations is defined for the state St [7:7].
para cualquier secuencia que tenga las mayores probabilidades hacia  las primeras $T$ observaciones, se puede definir para el estado $S_{t}$.

