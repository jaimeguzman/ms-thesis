\chapter[Experimentación]{Experimentación}\label{ch:experimetal-all}



% rand	Uniformly distributed random numbers
% randn	Normally distributed random numbers
% randi	Uniformly distributed pseudorandom integers
% randperm	Random permutation




% B = randi([1 17],20,100);


% B = randi(  [1 17], 20   , round( rand(1)*100 )   );



% save LALA B -ascii

% xlswrite('archivo.xls', datos obtenidos,'datos','A1:C2');


% La función "diary" nos permite salvar, en un fichero de texto, lo que aparezca por pantalla. Por ejemplo, el siguiente código:

% diary('diario1.txt')
% x = 3
% A = 10000;
% diary off






% Al cargar los datos desde Matlab, nos estaría creando una estructura. Para acceder a los datos y al texto, podríamos hacer:

% A = importdata('data.txt')
% B = A.data
% t1 = cell2mat(A.textdata)
% clear A



{
% Los objetivos no estan diferenciados entre generales y especıficos.
% Se presentan procesos que validan el trabajo comparando con otros metodos del estado del arte. 
% Se presenta una validacion deparametros,y todas las dimensiones que fueron planteadas son exploradas en profundidad.
% Se detalla y explica la recoleccion (de aplicar) y analisis de da- tos y resultados.
% Se distinguen los resultados segun las variables investigadas, y se examinan en virtud de lo explicado en el marco teorico.
%Se interpretan con claridad (es decir, se consideran distintos factores y anteceden- tes descritos hasta el momento) los resultados obtenidos.
}

Lo que se busca es un modelo de accesos de navegación secuencial creado por un algoritmo de compresión, Lempel Ziv,  para usarlo como un modelo  predicción. Se usará para buscar resultados sobre secuencias finitas discretas de \emph{webaccess logs}. Al momento de generar el árbol este creará una representación \emph{trie} de un diccionario de símbolos, se utilizará para realizar predicciones en secuencias discretas con distintos largos.

En base a lo anterior y teniendo en funcionamiento el algoritmo para crear un modelo de predicción, se integrará con el servidor de \emph{Machine Learning, PredictionIO} que ya se ha explicado anteriormente. Usaremos la misma \texttt{API }que ofrece la librería para poder realizar las evaluaciones de nuestras métricas, dado el dominio de nuestro problema la métrica a usar será \emph{Accuracy} (Exactitud) frente a distintas porciones de datos. Con el conjunto de datos que tenemos haremos variadas pruebas para ver métricas como Accuracy, usaremos \emph{cross validation} en distintos escenarios que nos permitirán tener información relevante de comportamiento de nuestro modelo propuesto en escenarios ideales como en escenarios reales.

%- Cross validation: This method is generally applied in machine-learning evaluation [14]. In our experiments, we performed a K-fold cross validation with k = 10. In this way, our dataset is 10 times split into 10 different sets of learning (90 
% of the total dataset) and testing (10 % of the total data).
%-Learning the model: We accomplished the learning step using different learning algorithms depending on

%%%%% Gueniche_Fournier-Viger_Raman_Tseng
%Tree is a type of prefix tree (aka trie). It contains all training sequences. Each tree node represents an item and each training sequence is represented by a path starting from the tree root and ending by an inner node or a leaf. Just like a prefix tree, the prediction tree is a compact representation of the training sequences. Sequences sharing a common prefix share a common path in the tree. The Lookup Table is an associative array which allows to locate any training sequences in the prediction tree with a constant access time. Finally the Inverted Index is a set of bit vectors that indicates for each item i from the alphabet Z, the set of sequences containing i.



\section{Nuestro Modelo de Predicción ML-LDC}\label{sec:nuestromodelopredict-mlldc}


%%%%%%% \cite{Moghaddam2009}

%The techniques that rely on sequential patterns such as Markov models and sequential association rules mining contain more precise information about users’ navigation behavior. 


%There is an arc from node A to B if and only if at some point in time a client accessed to B within w accesses after A, where w is the lookahead window size. The weight of the arc is the ratio of the number of accesses to B within a window after A to the number of accesses to A itself. 

Basados en un servidor de \emph{Machine Learning}, hemos desarrollado un motor de predicción con un algoritmo basado en \emph{Lempel} \& \emph{Ziv} \cite{ZivLempel1977}. Cada sesión es representada por un nodo y sus hijos. Sea la sesión \begin{equation}
Input = \{ A,A,A,B,A,B,B,B,B,B,A,A,B,C,C,D,D,C,B,A,A,A,A \}
\end{equation} la cual representaremos con nuestro modelo de predicción



\begin{figure}[h] 
	\centering
	\begin{forest} 
	[ $\epsilon$
		[A
			[AA
				[AAA]	
			]
			[AB
				[ABC]
			]
		]
		[B
			[BA]
			[BB
				[BBA]
			]
		]
		[C]
		[D
			[DC]
		]
	]
	\end{forest}
	\caption{Ejemplo de Árbol de Predicción basado en \texttt{LZ78}.}
	\label{fig:lztrie1}
\end{figure}

Dado nuestro modelo de predicción podemos determinar que nuestra salida resultante será:

\begin{equation}
Output = \{ A,AA,B,AB,BB,BBA,ABC,C,D,DC,BA,AAA \}
\end{equation}


Acotamos los siguientes casos en que nuestro Modelo de predicción funcionará:


\begin{enumerate}
	\item \textbf{Nodos Intermedios probabilidad Equivalente}
	
	Dada la $P( x | A\epsilon  )$, siendo $x$ la probabilidad de encontrar el siguiente símbolo. Este caso nos muestra que tenemos dos secuencias posibles $\{A,AB\}$, por lo cual podemos hacer la función $arg\ max(AA,AB)$ ó calcular una función $random(AA,AB)$, al ser un caso con solamente dos posibilidades tenemos solo un $50\%$ de éxito.
	
	
	\item \textbf{Nodos intermedios con un nodo hijo }
	
	Dada la $P( x | AB  )  = ABC$, ya que  el nodo $C$, es el único hijo por tanto tiene toda la certeza de ser la predicción acorde al árbol de entrenamiento.
		
		
		
	\item \textbf{Nodo hoja y vuelta a la raíz}	
	
	Este caso es uno de los más sencillos ya que nuestro modelo al no tener más secuencias para poder hacer las operaciones, se proyectará el árbol para todos los posibles accesos dentro de nuestro alfabeto. Para el caso $\Sigma = \{A,B,C,D \} $ y la probabilidad para cada acceso representado por símbolos es de $25\%$.
	
	
	Dada la probabilidad $P( x ) $ al momento de retornar a la raíz, la siguiente secuencia es absorbida por $\epsilon$.
	

\end{enumerate}







\section{Ambientes experimental}

Para los ambientes experimentales se han dispuestos dos máquinas para realizar las pruebas. 

\subsubsection{Máquinas}
	\begin{itemize}
		\setlength{\itemsep}{1pt}
		\setlength{\parskip}{0pt}
		\setlength{\parsep}{0pt}
		\item Procesador 2,8 GHz Intel Core i7, 16 GB de Memoria RAM y Sistema Operativo OSX
		\item Procesadores Intel Xeon E5-2670 v2 (Ivy Bridge) de alta frecuencia 32 vCPU, 244 GB de Memoria RAM y Sistema Operativo Ubuntu 14.14 
	\end{itemize}
	
Para el proceso de desarrollo con \emph{IntelliJ} y un conjunto de datos menores a 500 sesiones se usará la máquina con 16GB y para experimentos con sesiones mayores a 10000 sesiones de usuarios se usará la máquina 240GB.	
	

\subsubsection{Software utilizado}

	\begin{itemize}
		\setlength{\itemsep}{1pt}
		\setlength{\parskip}{0pt}
		\setlength{\parsep}{0pt}
		\item C++11
		\item Java  1.8
		\item Java(TM) SE Runtime Environment (build 1.8)
		\item Java HotSpot(TM) 64-Bit Server VM (build $25.51-b03$, mixed mode)
		\item Scala code runner version 2.11.7 -- Copyright 2002-2013, LAMP/EPFL
		\item SBT 0.13.9 
		\item Python 2.7.10
		\item GNU bash 3.2.57 $(x86_64-apple-darwin15)$
		\item Prediction.IO 0.9.4
		\item Elasticsearch 1.4.4	
		\item Apache Spark-1.4.1
		\item Hbase 1.0.0
		\item Zookeeper 
	\end{itemize}



% Selección de la métrica
% https://docs.prediction.io/evaluation/metricchoose/
% Explicación de evaluación
% https://docs.prediction.io/templates/recommendation/evaluation/#evaluation-data-generation




El motor de predicción es \emph{PredictionIO}, como se ha señalado anteriormente  es un entorno de desarrollo para desplegar servidores con algoritmos de \emph{Machine Learning} como  \emph{Decission Tree, K-Means, RNN} y todos los algoritmos ofrecidos por la librería de \emph{Apache Spark} y \emph{MLib}. Para desarrollar un motor que se acople con \emph{PredictionIO} se deberá seguir el patrón \emph{DASE}\ref{dase-algoritmo} y crear un modelo con persistencia en memoria que nos permita un acceso rápido a las predicciones por consulta.


Usaremos \emph{SBT} para gestionar todas las librerías que se requieran como dependencia. Inherentemente usaremos \emph{Java}, ya que el lenguaje \emph{Scala} corre sobre la \emph{Java Virtual Machine}. \emph{Prediction.IO} no solo ocupa \emph{Scala}, adicionalmente provee el uso de {Apache Spark} con sus librerías de \emph{MLIB} (\emph{Machine Learning Library}), \emph{Zookeeper}, \emph{Hbase} (Hadoop) y \emph{Elasticsearch}. Hemos utilizado \emph{Python} para realizar un cliente por línea de comando en el cual poder hacer pruebas y adicionalmente incluir un cliente que realice la carga de eventos desde nuestro set de datos experimental. Para mayor referencia de los clientes ver los códigos en anexos.





% Es una métrica que captura una porición correcta de toda la data a probar. 
% Una manera de modelar esto es para cada consulta que hacemos al predictor, damos un score de 1 y 0, luego podemos tomar el promedio de este score.

% PredictionIO sobre métricas


% PredictionIO has a [[AverageMetric]] helper class which provides this feature. This class takes 4 type parameters, [[EvalInfo]], [[Query]], [[PredictedResult]], and [[ActualResult]], these types can be found from the engine's signature. Line 5 below is the custom calculation.

%Precision is a metric for binary classifier capturing the portion of correction prediction among all positive predictions. We don't care about the cases where the QPA-tuple gives a negative prediction. (Recall that a binary classifier only provide two output values: positive and negative.) The following table illustrates all four cases:

%Calculating the precision metric is a slightly more involved procedure than calculating the accuracy metric as we have to specially handle the don't care negative cases.

%x PredictionIO provides a helper class OptionAverageMetric allows user to specify don't care values as None. It only aggregates the non-None values. Lines 3 to 4 is the method signature of calcuate method. The key difference is that the return value is a Option[Double], in contrast to Double for AverageMetric. This class only computes the average of Some(.) results. Lines 5 to 13 are the actual logic. The first if factors out the positively predicted case, and the computation is simliar to the accuracy metric. The negatively predicted case are the don't cares, which we return None.

% \subsection{Experimento comparativo con Frequent Sequency Pattern}


%\subsection{Decission Tree}
%\subsection{Asociation Rulz}





\section{Datos experimentales}
	\input{cap-experimental-dataexp}




\section{Experimentos}



Dentro de nuestro experimentos para probar la exactitud de nuestro modelo podemos demostrar que al tener una menor cantidad de secciones visitadas, la probabilidad de no acertar crece considerablemente.


Sea la siguiente sesión de un usuario 
$\{A , B , A  \}  $ para un alfabeto $\Sigma=\{A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q \} $





\begin{figure}[h] 
	\centering
	 \begin{tikzpicture}[level/.style={sibling distance=40mm/#1}]
		\node [circle,draw] (epsilon){$\varepsilon$}
		child { node [circle,draw] (A) {$A$} 
			child { node[circle,draw](AA){$AA$}  }
		}
		child {node [circle,draw] (B) {$B$} }
		;
		
		\end{tikzpicture}
	\caption{Ejemplo de Modelo de predicción basado en un \emph{trie} con \texttt{LZ78}.}
	\label{fig:sim}
\end{figure}



Podemos ver que a menor cantidad de símbolos en la sesión generan un árbol de menor altura y menos nodos, cada nodo como se ha señalado en el capitulo 4 representa un visita a una sección en particular de la web de \emph{MSNBC}. Cuando un \emph{webaccess} posee  pocas secciones o páginas visitadas, la proyección de probabilidades de los posibles símbolos en el alfabeto hace que la probabilidad del siguiente acceso sea equiprobable dentro del los símbolos de nuestro diccionario, de lo anterior convergemos en que mayor es el entrenamiento mejor será la predicción.

Dado el evento $x$  a predecir que pertenece a una secuencia discreta, la probabilidad de $P( x| AB  ) = A $, es el resultado de esta sesión de entrenamiento, pero la probabilidad $P(x | AAB) $, es desconocida.  Si extendemos los símbolos de este nodo cada nodo hijo tendría un probabilidad de $ \dfrac{1}{\Sigma} = \dfrac{1}{17} = 0.0588 $ o bien sería  $\dfrac{1}{ |\sigma| }$, siendo $|\sigma|$ el total de símbolos que se encuentran en el alfabeto. 

Para corroborar este comportamiento haremos distintos experimentos en distintos volúmenes de datos, usaremos una validación cruzada para medir el \emph{Accuracy}, la cual será nuestra métrica a utilizar.

Con esto demostraremos que secuencias con menores cantidad de símbolos generar un tipo de ruido a la métrica  que afecta en su a nuestra exactitud esperada, cuando hacemos nuevos ciclos de evaluaciones sobre el mayor orden, por otra parte veremos como con una menor cantidad de sesiones de entrenamiento podemos lograr un \emph{Accuracy} bastante optimista.



\vspace{1cm}
\begin{enumerate}
	% Idea de experimento con disminución del tamaño del alfabeto
	\item\label{exp1} \textbf{Experimento con sesiones de usuarios con datos generados de forma sintética}
	\input{cap-experimental-exp1}
	
	
	\newpage
	\item \label{exp2} \textbf{Sesiones con menor redundancia y  largo variable }
	\input{cap-experimental-exp2}


	\item \label{exp3}	
	\textbf{Sesiones con tamaño de secuencia constante}
	\input{cap-experimental-exp3}
	

	\item \label{exp4} \textbf{Secuencias de accesos con limite inferior 100 símbolos }
	\input{cap-experimental-exp4}


	\item \label{exp5}	
	\textbf{Sesiones con menos de 5 \emph{webaccess} para generar el \emph{trie}}
	\input{cap-experimental-exp5}	
	
	
	\item \label{exp6} 
	\textbf{Detección de Ruido en secuencias de acceso}
	
	Al modelar una navegación de usuario mediante un \emph{trie} basado en un algoritmo como \texttt{LZ78}, adoptamos un enfoque basado en la frecuencia por lo cual si realizamos experimentos para poder encontrar ruido veremos que que son secuencias de acceso comunes y estas no dan relevancia o aportan a la exactitud ó precisión del algoritmo.
	
	Sea la secuencia $\{A,A,A,A,A,A,A,A,A,A,A,A \}$ a la cual llamaremos secuencia $R$, si $A$ es representado por el \emph{home} ó página de inicio, esto da a interpretación que existe un usuario en su sesión $R$ que se encuentra accediendo constantemente a esta sección. Podemos señalar que esta es una sesión ruidosa si:
	
	\begin{equation}
		P( x | AAAAAAA)= A ,	
	\end{equation} pero siendo la sesión $R$ de tamaño = $12$, en el siguiente acceso tendremos una probabilidad equiprobable dentro de las secciones en nuestro alfabeto, la cual generará un probabilidad de éxito ''falso positivo''.
	
	En el siguiente experimento veremos como se comporta nuestro modelo dado entradas \emph{Ruidosas}. Además se mostrará como el árbol suele perder su balance a medida que va creciendo los niveles de altura. 
	
	
	
	Por otro lado teniendo la noción de como es el funcionamiento de un servidor \texttt{IIS}, y al ser una página con un gran número de visitas, podemos señalar que los datos proporcionados no son totalmente representativos de usuarios reales, ya que la web al bien indexada en los buscadores existen un cantidad indeterminada de \emph{Crawlers} ó \emph{Bots} que están constantemente generando accesos tanto para almacenar en caché páginas o generando accesos automatizados a ciertos secciones sin ser datos representativo. Dejamos como discusión que algoritmo se podría implementar para detección de estos patrones por las ramas que hemos generado para la detección de \emph{bots} o \emph{robots}.
	
	
	
	
	 
	
	%	\item  Dataset uniformes de largo acotado inferiormente y volumenes de alto tamaño.
\end{enumerate}








 



	% \begin{forest} 
	% 	[VP
	% 	[DP]
	% 	[V’
	% 	[V]
	% 	[DP]
	% 	]
	% 	]
	% \end{forest}



	% \begin{tikzpicture}[level/.style={sibling distance=60mm/#1}]
	% \node [circle,draw] (z){$n$}
	% child {node [circle,draw] (a) {$\frac{n}{2}$}
	% 	child {node [circle,draw] (b) {$\frac{n}{2^2}$}
	% 		child {node {$\vdots$}
	% 			child {node [circle,draw] (d) {$\frac{n}{2^k}$}}
	% 			child {node [circle,draw] (e) {$\frac{n}{2^k}$}}
	% 		} 
	% 		child {node {$\vdots$}}
	% 	}
	% 	child {node [circle,draw] (g) {$\frac{n}{2^2}$}
	% 		child {node {$\vdots$}}
	% 		child {node {$\vdots$}}
	% 	}
	% }
	% child {node [circle,draw] (j) {$\frac{n}{2}$}
	% 	child {node [circle,draw] (k) {$\frac{n}{2^2}$}
	% 		child {node {$\vdots$}}
	% 		child {node {$\vdots$}}
	% 	}
	% 	child {node [circle,draw] (l) {$\frac{n}{2^2}$}
	% 		child {node {$\vdots$}}
	% 		child {node (c){$\vdots$}
	% 			child {node [circle,draw] (o) {$\frac{n}{2^k}$}}
	% 			child {node [circle,draw] (p) {$\frac{n}{2^k}$}
	% 				child [grow=right] {node (q) {$=$} edge from parent[draw=none]
	% 					child [grow=right] {node (q) {$O_{k = \lg n}(n)$} edge from parent[draw=none]
	% 						child [grow=up] {node (r) {$\vdots$} edge from parent[draw=none]
	% 							child [grow=up] {node (s) {$O_2(n)$} edge from parent[draw=none]
	% 								child [grow=up] {node (t) {$O_1(n)$} edge from parent[draw=none]
	% 									child [grow=up] {node (u) {$O_0(n)$} edge from parent[draw=none]}
	% 								}
	% 							}
	% 						}
	% 						child [grow=down] {node (v) {$O(n \cdot \lg n)$}edge from parent[draw=none]}
	% 					}
	% 				}
	% 			}
	% 		}
	% 	}
	% };
	% \path (a) -- (j) node [midway] {+};
	% \path (b) -- (g) node [midway] {+};
	% \path (k) -- (l) node [midway] {+};
	% \path (k) -- (g) node [midway] {+};
	% \path (d) -- (e) node [midway] {+};
	% \path (o) -- (p) node [midway] {+};
	% \path (o) -- (e) node (x) [midway] {$\cdots$}
	% child [grow=down] {
	% 	node (y) {$O\left(\displaystyle\sum_{i = 0}^k 2^i \cdot \frac{n}{2^i}\right)$}
	% 	edge from parent[draw=none]
	% };
	% \path (q) -- (r) node [midway] {+};
	% \path (s) -- (r) node [midway] {+};
	% \path (s) -- (t) node [midway] {+};
	% \path (s) -- (l) node [midway] {=};
	% \path (t) -- (u) node [midway] {+};
	% \path (z) -- (u) node [midway] {=};
	% \path (j) -- (t) node [midway] {=};
	% \path (y) -- (x) node [midway] {$\Downarrow$};
	% \path (v) -- (y)
	% node (w) [midway] {$O\left(\displaystyle\sum_{i = 0}^k n\right) = O(k \cdot n)$};
	% \path (q) -- (v) node [midway] {=};
	% \path (e) -- (x) node [midway] {+};
	% \path (o) -- (x) node [midway] {+};
	% \path (y) -- (w) node [midway] {$=$};
	% \path (v) -- (w) node [midway] {$\Leftrightarrow$};
	% \path (r) -- (c) node [midway] {$\cdots$};
	% \end{tikzpicture}



%Las conclusiones son deducidas logicamen- te de los resultados obtenidos y de la interpretacionpresen- tada, ademas estan conectadas al marco teorico.
%Las conclusiones muestran el logro de los ob jetivos.
%Se presentan proyec- ciones validas y valio- sas a partir del traba- jo realizado.
%Se detallan claramen- te las limitaciones del traba jo realizado.




 


 
%%%%%%%%
%%%%%%%%


 

El orden de como se ingresan las sesiones afecta directamente proporcional a la construcción del modelo \emph{trie},  por lo cual es un factor  \emph{FIFO} al momento de crear, lo primero que lee es lo primero que entrena por lo cual se debiese tener un criterio para ordenar los \emph{webaccess} antes de poder pasarlos al entrenador, que implica antes de la construcción.

El modelo propuesto, básicamente es un compresor el cual no toma decisiones, una posible mejora sería implementar un árbol de decisiones con algún criterio para decidir que entrenar y que no, estos árboles pueden estar dentro del \emph{trie} para
poder elegir secuencias optimo acorde a los criterios históricos, así podría darse el caso de ser un compresor--predictor  \emph{mas inteligente}.



















\vspace{2cm}
\section{Conclusiones y Contribuciones}\label{ch:conlusion-contrib-all}
	\input{contrib-conlusion}






\newpage
\subsection{Trabajos Futuro}

Esta memoria forma parte del plan de continuidad en el postgrado de la Escuela de Ingeniería Informática y telecomunicaciones, por lo cual se desea profundizar este trabajo en las discusiones realizadas. Los temas deseados por abarcar:

\begin{itemize}

\item Crear un estudio comparativo con Modelos de \emph{Machine Learning} como (\emph{RNN}) Redes Neuronales, Reglas de Asociación, \emph{Deep Learning} y algoritmo de tipo \emph{Frequent Pattern Growth}.

\item Técnicas para mejorar el modelo de predicción 
\item Mejorar la implementación de \texttt{LZ78}, realizado con lenguaje funcional y objetos(\emph{Scala}) y hacer una comparación de rendimientos contra implementaciones clásicas en lenguajes de más bajo nivel (\texttt{C++}).


\item Crear técnicas como la usada por Claude \etal~\cite{Claude2014}, para crear representaciones eficientes en función de este modelo predictivo.


\item Investigar los factores teóricos y técnicos para poder mejorar la exactitud de la predicción.

\item Ambiciosamente a realizar un estudio comparativo para encontrar puntos en común de estas áreas de la ciencia de la computación, se desea crear un nuevo algoritmo basado en la familia de \emph{Lempel Ziv}, el cual pueda tener un complemento para la selección de sesiones antes ser ingresadas en el modelo de navegación predictivo. 


	
\end{itemize}	






 








