\chapter[Experimental]{Experimental}

%Los ob jetivos no estan diferenciados entre generales y especıficos.

%e presentan proce- sos que validan el tra- ba jo comparando con otros metodos del es- tado del arte. Se pre- senta una validacion deparametros,yto- das las dimensiones que fueron plantea- das son exploradas en profundidad.


%Se detalla y explica la recoleccion (de apli- car) y analisis de da- tos y resultados.
%Se distinguen los re- sultados segun las va- riables investigadas, y se examinan en virtud de lo explicado en el marco teorico.
%Se interpretan con claridad (es decir, se consideran distintos factores y anteceden- tes descritos hasta el momento) los resultados obtenidos.


Lo que se busca es usar como un modelo de predicción un algoritmo de la familia de compresores de Lempel Ziv. Se usará para predecir secuencias finitas discretas de accesos web. Al momento de generar el árbol este creará una representación trie de un diccionario de símbolos, el cual no utilizaremos para poder hacer predicciones.

En base a lo anterior y teniendo funcionando el algoritmo para crear un modelo de predicción, la integraremos con el servidor de Machine Learning, Prediction.IO que ya se ha explicado anteriormente.



%\subsection{Ambiente experimental}

Para los ambientes experimentales se han dispuestos dos máquinas para realizar las pruebas.

\subsubsection{Máquinas}
\begin{itemize}
	\item Procesador 2,8 GHz Intel Core i7, 16 GB de Memoria RAM y Sistema Operativo OSX
	\item Procesadores Intel Xeon E5-2670 v2 (Ivy Bridge) de alta frecuencia 32 vCPU, 244 GB de Memoria RAM y Sistema Operativo Ubuntu 14.14 
\end{itemize}

\subsubsection{Software}

\begin{itemize}
	\item C++11
	\item Java  1.8
	\item Java(TM) SE Runtime Environment (build 1.8)
	\item Java HotSpot(TM) 64-Bit Server VM (build $25.51-b03$, mixed mode)
	\item Scala code runner version 2.11.7 -- Copyright 2002-2013, LAMP/EPFL
	\item SBT 0.13.9 
	\item Python 2.7.10
	\item Prediction.IO 0.9.4
	\item Elasticsearch 1.4.4	
	\item Apache Spark-1.4.1
	\item Hbase 1.0.0
	\item Zookeeper 

\end{itemize}


\subsection{Datos Experimentales}
% Cita a Rkonow Claude & Navarro

Se usará las secuencias disponibles de acceso web pública de los sitios Msnbc. El set de datos provienen de los registros de un servidor IIS (Internet Information Services) msnbc.com de un día completo de la fecha  28 de Septiembre de 1999. 
Contiene secuencias de acceso web de 989,818 usuarios con un promedio de 5,7  categorías Página web visitas por secuencia, el tamaño de letras de este conjunto de datos es $\sigma \ = 17$.


Ejemplo de estructura de Dataset MSNBC :
\vspace{1cm}

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
% Different categories found in input file:

frontpage news tech local opinion on-air misc weather msn-news health living business msn-sports sports summary bbs travel


% Sequences:

A A 
B 
C B B D B B B C C 
E 
A 
F 
A A 
F 
F G G G F F H H H H 
F I D D D J C J E J D D D 
A A A K A A A 
L L 
A A 
H H H H H H 
\end{lstlisting}





\begin{table}[]
	\centering
	\caption{Para poder interpretar la entrada anterior se debe tener esta relación de símbolos con respecto a las páginas}
	\label{my-label}
	\begin{tabular}{cl}
		Page       & Symbol \\ \cline{1-2}
		frontpage  & A      \\
		news       & B      \\
		tech       & C      \\
		local      & D      \\
		opinion    & E      \\
		on-air     & F      \\
		misc       & G      \\
		weather    & H      \\
		msn-news   & I      \\
		health     & J      \\
		living     & K      \\
		business   & L      \\
		msn-sports & M      \\
		sports     & N      \\
		summary    & O      \\
		bbs        & P      \\
		travel     & Q      \\ 
	\end{tabular}
\end{table}


\begin{tikzpicture}
\begin{axis}[
xlabel=Cost,
ylabel=Error]
\addplot[color=red,mark=x] coordinates {
	(2,-2.8559703)
	(3,-3.5301677)
	(4,-4.3050655)
	(5,-5.1413136)
	(6,-6.0322865)
	(7,-6.9675052)
	(8,-7.9377747)
};
\end{axis}
\end{tikzpicture}


\begin{forest} 
	[VP
	[DP]
	[V’
	[V]
	[DP]
	]
	]
\end{forest}


%Las conclusiones son deducidas logicamen- te de los resultados obtenidos y de la interpretacionpresen- tada, ademas estan conectadas al marco teorico.
%Las conclusiones muestran el logro de los ob jetivos.
%Se presentan proyec- ciones validas y valio- sas a partir del traba- jo realizado.
%Se detallan claramen- te las limitaciones del traba jo realizado.



\subsection{Metodologías}

	%- Cross validation: This method is generally applied in machine-learning evaluation [14]. In our experiments, we performed a K-fold cross validation with k = 10. In this way, our dataset is 10 times split into 10 different sets of learning (90 
	% of the total dataset) and testing (10 % of the total data).
	%-Learning the model: We accomplished the learning step using different learning algorithms depending on




\subsection{Resultados Experimentales}


\begin{enumerate}
	
	\item \textbf{ Experimento con Largo de Ventana} 
	
	Cual podria ser el optimo de la ventana
	Que ventana o cual corre mejor
	
	
	
	\item Experimento con el Tamaño del Set de datos de Entrenamiento
	
	\item Experimento con Predicciones con Ruido
	
	\item Cross Validation
	
	
	\item Accurracy
	
	
	\item Experimento comparativo con Frequente Sequency Pattern
	
	\item Decission Tree
	
	\item Asociation Rulz
		
	
	
	
	
	
\end{enumerate}




\section{Conclusiones y Resultados}



%In this paper we studied the empirical performance of a number of prominent prediction algorithms. We focused on prediction settings that are more closely related to those required

%%%%%%%%% On Prediction Using Variable Order Markov Models

%$%%%%%%%%
%%n this paper we studied the empirical performance of a number of prominent prediction algorithms. We focused on prediction settings that are more closely related to those required
%On Prediction Using Variable Order Markov Models
%by machine learning practitioners dealing with discrete sequences.
%However, somewhat surprisingly, the best predictor under the log-loss is not the best classifier. On the contrary, the consistently best protein classifier is based on the mediocre lz-ms predictor! This algo- rithm is a simple modification of the well-known Lempel-Ziv-78 (lz78) prediction algorithm, which can capture VMMs with large contexts. The surprisingly good classification accuracy achieved by this algorithm may be of independent interest to protein analysis research and clearly deserves further investigatio 
% Genero toda las referencias para demostrar el uso de la bibliografía
% No es necesario que utilice este comando en su document
%
%Conclusion of this paper Gopalratnam Cook
%alz effectively models sequential processes, and is extremely useful for prediction of processes where events are dependent on the previous event history. This is because of the ability of the algorithm to build an accurate model of the source of the events being generated, a feature inherited from its information theoretic background and the LZ78 text compression algorithm. 
%The effectiveness of the method for learning a measure of time can also be attributed to fact that ALZ is a strong sequential predictor. The sound theoretical principles on which ALZ is founded also mean that ALZ is an optimal Universal Predictor, and can be used in a variety of prediction scenarios.
%conclusion lcoa
%Dado que la myora de los predictores funcionan de 
%manera offline, uno de los aporte de tener estar estructura de algoritmos como servicios es poder tener un motor de prediccion en linea.
