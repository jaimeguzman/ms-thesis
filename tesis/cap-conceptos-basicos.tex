\chapter[Conceptos Básicos]{Conceptos básicos y trabajos relacionados} \label{ch:Conceptos-Basicos}





En este capítulo se explicarán brevemente los conceptos principales que se usarán en los siguientes capítulos.


\section{Conceptos}

\subsection{Access Log}\label{concept-accesslog}

Los \emph{Access Log} son registros que se almacenan en un servidor, los cuales dependiendo del servidor, sistema operativo y las configuraciones del ambiente pueden tener mayor o menor información. Cuando los usuarios acceden a diversos sitios web, estos registros dejan una gran cantidad de información, un ejemplo se puede ver en la Figura~\ref{fig:accesslog-apache-teleton}. Si se extraen de forma correcta se puede obtener patrones de navegación de usuarios. 


\subsection{Árboles Trie} \label{concept-trie}

Los \emph{trie} son un tipo de árbol de prefijos, estructuras de datos en forma de árbol que almacenan datos en sus nodos y es muy fácil la recuperación de información de estos. Se caracterizan por ser un conjunto de llaves que se representan en el árbol y sus nodos internos representan la información, en nuestro caso una secuencia de acceso o un símbolo (secuencia de largo 1). 

Un árbol es una estructura general de nodos recursivos. Hay muchos tipos de árboles. Los populares son árbol binario y el árbol balanceado. Un \emph{trie} es conocido por muchos nombres incluyendo árbol prefijo, árbol de búsqueda digital, árbol de la recuperación (de ahí el nombre de ``\emph{trie}'', por la palabra del inglés recuperación, \emph{retrieval}).

Cada tipo de árbol tiene distinta finalidad, estructura y comportamiento. Por ejemplo, un árbol binario almacena una colección de elementos comparables (por ejemplo, números). Por lo tanto, se puede utilizar para almacenar un conjunto de números, o al índice de otros datos que pueden ser representados por los números (por ejemplo, objetos que pueden ser \emph{hash}). Su estructura está ordenada por lo que se puede buscar rápidamente para encontrar nodo. Otras estructuras de árbol, como un árbol balanceado son similares en principio al \emph{trie} que se implementará en la etapa experimental.

Un \emph{trie} representa una forma  estructurada de nodos, la cual puede almacenar secuencias. % (ver el artículo de wiki). 
Es muy diferente cuando almacena secuencias de valores en lugar de valores individuales. Cada nivel representa un incremento en la altura del árbol.
%'¿cuál es el valor del punto I de la lista de entrada'. Esto es diferente a un árbol binario que compara el valor buscado único a cada nodo.


Durante este trabajo mostraremos que nuestro modelo de predicción usa un \emph{trie}, para representar un diccionario, en los cuales podemos señalar las siguientes operaciones disponibles:

	\begin{itemize}	
		\item \textbf{findByPrefix(x):}  Retornar una una lista de todos los nodos hasta llegar a un nodo que posea un \emph{String} de parámetro equivalente a $x$.
		
		\item \textbf{contains(x):} Retornar una lista de nodos intermedios hasta que el contenido del nodo final sea hoja o el intermedio corresponda a valor de la secuencia \emph{String} $x$.
		
		\item \textbf{remove(x):} Retorna \emph{true} o \emph{false} cuando es posible remover el nodo con el contenido equivalente a $x$.
		
		\item \textbf{pathTo(x):} Retorna una lista de nodos hasta llegar a un nodo que posea el contenido equivalente del valor $x$.
	\end{itemize}







\subsection{Alfabeto} \label{concept-alphabet}


Un alfabeto es un conjunto ordenado de elementos. Una de sus características es que la cantidad de elementos puede ser de valores  discreto, representaremos por $\Sigma$ al alfabeto que usaremos y una de las características básica de este alfabeto posee $\sigma^{n}$ símbolos, tal que $\sigma^{n}= \sigma_{1}, \dots, \sigma_{n},\ \sigma_{i} \in \Sigma$, donde {$\sigma_{1}$}\label{concept-alphabet-homepage} es definido como la página inicial de una cierta secuencia  o sesión de usuario. Sea $|\Sigma|$ la longitud de secuencia o la cardinalidad del alfabeto daremos como restricción que $|\Sigma| \geq 2$ símbolos~\cite{Dmitry2002} necesarios para realizar experimentos acotados. Posteriormente en el capítulo experimental~(\ref{ch:experimetal-all}) usaremos un conjunto de datos de tamaño $|\Sigma| =\ 17\  \mbox{símbolos}$, para datos reales recolectados de \emph{MSNBC}\cite{Claude2014} y un $|\Sigma|$ variable para experimentos con datos sintéticos.

El alfabeto sera utilizado simbólicamente como la representación de varios nodos contenido en un \emph{trie} que {modela la navegación de usuarios}~(\ref{sec:nuestromodelopredict-mlldc}) para un sitio \emph{web}.





\subsection{Secuencias discretas}\label{concept-discret-seq}

Definimos una secuencia de accesos discreta y finita  $S$ , dado ciertos accesos de usuarios que tiene una \emph{web}, lo anterior es acotado por el concepto de \emph{sesión de navegación}, que es desde que se inicia la el primer acceso, $\sigma_{1}$~(\ref{concept-alphabet-homepage}) por parte de un usuario hasta su que finaliza su navegación. Las secuencias de navegación serán de tamaño $S\ \leq 1$ y  no superior a la cardinalidad del alfabeto $|\Sigma|$.



% Compresor tonto o Machine Learning lento para predecir
\subsection{Lossless Data Compression (LDC)} \label{concept-LDC}

La compresión sin pérdida o \emph{LDC}, es el arte de poder comprimir \emph{bits} y poder hacer el proceso inverso, es decir poder codificar y decodificar. En capítulos posteriores (\ref{ch:Compresion-Machine-Learning}) se detallará más sobre el tema compresión y como esta área ayuda a crear un modelo de predicción.



\subsection{Motor de Predicción}\label{concept-enginepredict}

Los motores de Predicción son la parte fundamental de un sistema predictivo, dirigido a adivinar el futuro eventos dado un entrenamiento para un escenario o conjunto de datos en particular. La salida del motor de predicción es un evento siguiente. Para nuestro trabajo la salida se compone de un símbolo representando la dirección \emph{url} o una sección en particular de una cierta \emph{web}. 
% que son propensos a ser solicitado por el usuario en las solicitudes posteriores.

 


\subsection{Resilient Distributed Datasets }\label{concept-RDD}

	Los \texttt{RDD}, permiten que en un servidor de \emph{Machine Learning } pueda mantener un modelo o motor de aprendizaje persistente sin importar en el flujo que se encuentre.

	Esta estructura es fundamental dentro de la librería que se introducirá mas adelante, \emph{Apache Spark}. Esta estructura es una colección distribuida de objetos inmutables, cada 
	set de datos en un \texttt{RDD} es divido en particiones lógicas, las cuales puedes ser computadas en distintos cluster. Los \texttt{RDD} pueden contener cualquier tipo de objeto de los siguientes lenguajes: \emph{Python}, \emph{Scala} y \emph{Java}, incluyendo clases definidas por el usuario. 

	Formalmente los \texttt{RDD} son solo de lectura, una colección de objetos divididos. Estos pueden ser creados a través de  operaciones deterministas en una cierta tabla o un almacenamiento externo u otra \texttt{RDD}.
	Otra de las características de los \texttt{RDD}, es que son colecciones de elementos tolerantes a fallas que pueden ser operadas en si mismas o en paralelo.
	\emph{Apache Spark} hace el uso del concepto de \texttt{RDD} para lograr rapidez y eficiencia en las operaciones de \emph{MapReduce}, de ser requeridas. Destacamos la escabilidad de esta librería para un gran nivel de cómputo, pero en este trabajo no se explicará el uso de \emph{Spark}, pero si se utilizarán algunos conceptos como \texttt{RDD} y otros.




\subsection{Data Source y Dataset }

	Los \emph{Data Source} son distintas fuentes de datos que podemos ir sacando set de datos (\emph{Dataset}). Ambos conceptos están enfocados a proveer información tanto para el servidor de \emph{Machine Learning}, como para el procesamiento y análisis.
	En este trabajo el dataset con que realizaremos nuestro estudio son los registros de accesos de la web española \emph{MSNBC}\cite{Claude2014}, los cuales representan aproximadamente 1.000.000 de registros de \emph{webaccess log}.

	Nuestro set de  datos esta basado en los registros (webaccess log), ya previamente depurados con una representación numérica desde 0 hasta 16, el cual como antes ya se ha señalado estará relacionado al concepto de alfabeto. También crearemos \emph{dataset} sintéticos para poder realizar depuraciones de nuestra implementación y casos de bordes.
	
	 



 



% \subsection{DataFrame}


	% A DataFrame is a distributed collection of data, which is organized into named columns. Conceptually, it is equivalent to relational tables with good optimization techniques.
	% Here is a set of few characteristic features of DataFrame −
	% Ability to process the data in the size of Kilobytes to Petabytes on a single node cluster to large cluster.
	% Supports different data formats (Avro, csv, elastic search, and Cassandra) and storage systems (HDFS, HIVE tables, mysql, etc).
	% State of art optimization and code generation through the Spark SQL Catalyst optimizer (tree transformation framework).
	% Can be easily integrated with all Big Data tools and frameworks via Spark-Core.
	% Provides API for Python, Java, Scala, and R Programming.



% easy text
% https://es.wikipedia.org/wiki/Trie
%Definición interpretada de esot

%\subsection{Cadenas de Markov}





\subsection{Transferencia de Estado Representacional}~\label{concept-rest}

Es un estilo de desarrollo de software para sistemas distribuidos mediante Internet. El uso de REST, de sus siglas en ingles, ha sido adoptado mucho más adoptado que  \emph{Simple Object Access Protocol}, ya que los servicios \emph{REST} aprovechan mayor cantidad el ancho de banda, lo que hace que sea una mejor opción para su uso a través de Internet, los mensajes tanto originados por el servidor o cliente puede ser enviados en formato \emph{xml} o \emph{json}. 



%@TODO:
% Este tema debería detallarse en las siguientes secciones
\section{Trabajos relacionados}

En la literatura, el tema de la predicción en la web se ha presentado como un tema recurrente provocando bastante atención durante los último años y ha sido tratado por varios autores de áreas de \emph{Machine Learning} y \emph{Lossless Data Compression}. Tenemos los siguientes trabajos de interés:


\input{related-work}


