\chapter[Conceptos B√°sicos]{Conceptos B√°sicos}
\label{ch:Conceptos-Basicos}





En este capitulo se introducira los conceptos principales que se trabajar√°n en los siguientes capitulos:




\subsection{Access Log}

Son los registros que se almacenan en un servidor, los cuales dependiendo de sistema operativo pueden tener mayor o menor informaci√≥n. Cuando los usuarios acceden a los sitios web, estos  suelen dejar una gran cantidad de informaci√≥n de acceso, la cual si es extra√≠da razonable puede ayudar a los administradores de sitio web para obtener acceso a los patrones de los usuarios. 


\subsection{√Årboles Trie}

%%%%% Gueniche_Fournier-Viger_Raman_Tseng
%Tree is a type of prefix tree (aka trie). It contains all training sequences. Each tree node represents an item and each training sequence is represented by a path starting from the tree root and ending by an inner node or a leaf. Just like a prefix tree, the prediction tree is a compact representation of the training sequences. Sequences sharing a common prefix share a common path in the tree. The Lookup Table is an associative array which allows to locate any training sequences in the prediction tree with a constant access time. Finally the Inverted Index is a set of bit vectors that indicates for each item i from the alphabet Z, the set of sequences containing i.


Son estructuras de datos de tipo de √°rbol que almacenan datos en nodos y es de muy f√°cil la recuperaci√≥n de informaci√≥n de estos mismo. Sus caracter√≠sticas generales es ser un conjunto de llaves las cuales se representan en el arbol y sus nodos internos representan la informaci√≥n, en nuestro caso una caracter o string de tama√±o 1.

Un √°rbol es una estructura general de nodos recursivos. Hay muchos tipos de √°rboles. Los populares son √°rbol binario y el √°rbol de equilibrado. Un Trie es una especie de √°rbol, conocido por muchos nombres incluyendo √°rbol prefijo, √°rbol de b√∫squeda digital, √°rbol de la recuperaci√≥n (de ah√≠ el nombre de \'trie\').

Cada especie de √°rbol tiene distinta finalidad, estructura y comportamiento. Por ejemplo, un √°rbol binario almacena una colecci√≥n de elementos comparables (por ejemplo, n√∫meros). Por lo tanto, se puede utilizar para almacenar un conjunto de n√∫meros, o al √≠ndice de otros datos que pueden ser representados por los n√∫meros (por ejemplo, objetos que pueden ser hash). Su estructura est√° ordenada por lo que se puede buscar r√°pidamente para encontrar un solo art√≠culo. Otras estructuras de √°rbol, como √°rbol de equilibrado son similares en principio.

Un trie representa una secuencia en su estructura (ver el art√≠culo de wiki). Es muy diferente en que la almacena secuencias de valores en lugar de valores individuales individuales. Cada nivel de recursividad dice 
%'¬øcu√°l es el valor del punto I de la lista de entrada'. Esto es diferente a un √°rbol binario que compara el valor buscado √∫nico a cada nodo.


Durante este trabajo mostraremos que nuestro modelo de predicci√≥n usa un \emph{Trie}, para representan un diccionario, en los cuales podemos se√±ar la siguientes operaciones disponibles:

	\begin{itemize}
	\item 

	\end{itemize}







\subsection{Alfabeto}

Un alfabeto discreto $A$ consiste en $M > 1$ simbolos.
Dado un volumen de datos experimental, nuestro alfabeto es representado simb√≥licamente como la representaci√≥n de un nodo de contenido de un sitio web.
Donde $A$, puede ser definido como la p√°gina inical. Este alfabeto es finito y acotoda por la mineria de datos de uso web.

%Let A be a discrete alphabet consisting of M  2 symbols; x = x ; : : : ; x ; x 2 A
% be rst n symbols of message; jj be the length of sequence  or the cardinality of
% set . The probability of symbol x = a 2 A for a source with memory depends on
% current context s = x ; : : : ; x 2 A ; d  D. The set of all possible contexts can
% be presented as nodes in M -ary tree with depth D. Context (sequence) s describes a
% path from tree root to the current node also denoted as s.
% Usually the true conditional probabilities are unknown and the coding conditional
% pr ob abilitiesq(ajs) depend on characteristics of one or sev eralsubsequences x (s),
% x (s) is the subsequence of all symbols x such that x ; : : : ; x
% = s . These
% characteristics are: frequency f (ajs) = f (ajx (s)) of symbol a in x (s), alphabet
% A(s) = A(s; x (s)) = fa : f (ajs) > 0g, its cardinality m(s) = jA(s)j etc. Even at
% small D, the n umber of model states is big, subsequences x (s) are short ina verage,
% and their statistics is insu√Ücient for eective compression.
% PPM algorithm [2] is based on an (implicit) assumption: the longer is the common initial part of contexts, the more (in average)similarity there is between their
% conditional probability distributions. High PPM e√Üciency means this assumption is
% fair forthe majority of real sources.



\subsection{Secuencias discretas}

Definimos una secuencia de accesos discreta y finita, dado los acccesos que tiene un usuario frente a una web, lo anterio es acotado por el concepto de sesi√≥n, el cual es desde que se inicia la navegaci√≥n, es decir secuencia de tama√±o $Seq\ \leq 1$ y de tamalo no superior a un alfabeto $A$.


% Compresor tonto o Machine Learning lento para predecir
\subsection{Lossless Data Compression}

La compresi√≥n sin p√©rdida o LDC, es el arte de poder comprimir bits y poder hacer el proceso inverso, es decir tener la posibilidad de codificar y decodificar. En capitulos posteriores introduciremos mas el tema compresi√≥n y como este ayuda a crear un modelo de predicci√≥n.


\subsection{Motor de Predicci√≥n}

Es la parte fundamental de un sistema dirigida a adivinar el futuro acceso de un usuario. La salida del motor de predicci√≥n es la siguiente p√°gina, que se compone de un s√≠mbolo representando la direcci√≥n URL o una secci√≥n en particular de un cierta web. 
% que son propensos a ser solicitado por el usuario en las solicitudes posteriores.



\subsection{Resilient Distributed Datasets }

	Los RDD, permiten que en un servidor de Machine Learning pueda mantener un modelo o motor de aprendizaje persitente sin importan el flujo en que se encuentre.

	Esta estructura es fundamental dentro de la liber√≠a que se introducir√° mas adelante, Apache Spark. Esta estructura es una colecci√≥n distribuida de objetos Inmutable, cada 
	set de datos en un RDD es divido en particiones l√≥gicas, las cuales puedes ser computdadas en distintos Clusters. Los RDD pueden contener cualquier tipo de objeto de los siguientes lenguajes: Python, Scala y Java, incluyendo clases definidas por el usuario. 

	Formalmente los RDD son solo de lectura, una colecci√≥n de objetos particionada. Estos pueden ser creados atrav√©s de  operaciones determinstisticas en una cierta tabla o un almacenamiento externo √≥ otra RDD.
	Otra de las car√°cteristicas de los RDD, es que son colecciones de elementos toleantes a fallas que puede ser operadas en si mismas o en paralelo.
	Apache Spark hace el uso del concepto de RDD para lograr rapidez y efecienciencia en las operaciones de MapReduce, de ser requeridas. Destacamos la escabilidad de esta liber√≠a para un gran nivel de computo, pero en este trabajo no se explicar√° el uso de Spark, pero si se utilizar√°n algunos conceptos como RDD y otros.




\subsection{Data Source y Dataset }

	Ambos conceptos est√°n focalizados en  proveer informaci√≥n tanto para el servidor de Machine Learning, como para el procesamiento y analisis.
	En este trabajo los dataset a estudiar son un los registros de accesos de la web espa√±ola Prisa, los cuales representan 1.000.000 de registros correspondientes.

	Nuestro set de  datos esta basado en los registros (webaccess log), ya previamente depurados con una representaci√≥n num√©rica desde 0 hasta 17 

	frontpage news tech local opinion on-air misc weather msn-news health living business msn-sports sports summary bbs travel



% \subsection{DataFrame}


	% A DataFrame is a distributed collection of data, which is organized into named columns. Conceptually, it is equivalent to relational tables with good optimization techniques.
	% Here is a set of few characteristic features of DataFrame ‚àí
	% Ability to process the data in the size of Kilobytes to Petabytes on a single node cluster to large cluster.
	% Supports different data formats (Avro, csv, elastic search, and Cassandra) and storage systems (HDFS, HIVE tables, mysql, etc).
	% State of art optimization and code generation through the Spark SQL Catalyst optimizer (tree transformation framework).
	% Can be easily integrated with all Big Data tools and frameworks via Spark-Core.
	% Provides API for Python, Java, Scala, and R Programming.



% easy text
% https://es.wikipedia.org/wiki/Trie
%Definici√≥n interpretada de esot

%\subsection{Cadenas de Markov}





%\subsection{Transferencia de Estado Representacional}

% REST es un estilo de arquitectura software para sistemas hipermedia distribuidos como la World Wide Web. El t√©rmino se origin√≥ en el a√±o 2000, en una tesis doctoral sobre la web escrita por Roy Fielding, uno de los principales autores de la especificaci√≥n del protocolo HTTP y ha pasado a ser ampliamente utilizado por la comunidad de 
%@TODO: poner una sucia referencia a wiki o algun paper mas sensato

%@TODO:
% Este tema deber√≠a detallarse en las siguientes secciones
\section{Trabajos Relacionados}

En la literatura, el tema de la predicci√≥n en la web se ha presentado como un tema concurrente tomando bastante atenci√≥n durante los √∫ltimo a√±os y ha sido abarcado por 
varios autores. Tenemos los siguientes trabajos de inter√©s:

%%%%%%%Moghaddam_Kabir
%Various models have been proposed for modeling the user navigation behavior and predicting the next requests of users. According to [12], association rules, sequential pattern discovery, clustering, and classification are most popular methods for web usage mining. Collaborative filtering is another method for modeling users' behaviors. Association rules [6] were proposed to capture the co- occurrences of buying different items in a supermarket shopping. Association rules indicate groups that are related together. Methods that use association rules can be found in [6, 7]. Collaborative filtering techniques are often based on matching the current user's profile against similar data obtained by the system over time from other users. It tries to make useful recommendations users based on discovered cluster of similar categories. But for web sites where the number of web pages is quite large it can be quite inefficient.



\input{related-work}


