\chapter[Conceptos B√°sicos]{Conceptos B√°sicos}
\label{ch:Conceptos-Basicos}





En este cap√≠tulo se introducir√°n los conceptos principales que se trabajar√°n en los siguientes cap√≠tulos:


\section{Conceptos}

\subsection{Access Log}

Los \emph{Access Log} son los registros que se almacenan en un servidor, los cuales dependiendo del servidor, sistema operativo y las configuraciones del ambiente pueda tener mayor o menor informaci√≥n. Cuando los usuarios acceden a los sitios web, estos registros dejan una gran cantidad de informaci√≥n de acceso, extrayendo en forma correcta esta  se puede obtener patrones de accesos de usuarios. 


\subsection{√Årboles Trie}

Los \emph{Trie} es un tipo de √°rbol de pre-fijos, son estructuras de datos en forma de √°rbol que almacenan datos en sus nodos y es muy f√°cil la recuperaci√≥n de informaci√≥n de estos. Se caracterizan por ser un conjunto de llaves que se representan en el √°rbol y sus nodos internos representan la informaci√≥n, en nuestro caso una secuencia de acceso o un s√≠mbolo (secuencia de largo 1). 

Un √°rbol es una estructura general de nodos recursivos. Hay muchos tipos de √°rboles. Los populares son √°rbol binario y el √°rbol balanceado. Un Trie es conocido por muchos nombres incluyendo √°rbol prefijo, √°rbol de b√∫squeda digital, √°rbol de la recuperaci√≥n (de ah√≠ el nombre de ''trie'', por la palabra del ingles recuperaci√≥n, ''retrieval'').

Cada tipo de √°rbol tiene distinta finalidad, estructura y comportamiento. Por ejemplo, un √°rbol binario almacena una colecci√≥n de elementos comparables (por ejemplo, n√∫meros). Por lo tanto, se puede utilizar para almacenar un conjunto de n√∫meros, o al √≠ndice de otros datos que pueden ser representados por los n√∫meros (por ejemplo, objetos que pueden ser \emph{hash}). Su estructura est√° ordenada por lo que se puede buscar r√°pidamente para encontrar nodo. Otras estructuras de √°rbol, como un √°rbol balanceado son similares en principio al trie que se implementar√° en la etapa experimental.

Un \emph{Trie} representa una forma  estructurada de nodos, la cual puede almacenar secuencias. % (ver el art√≠culo de wiki). 
Es muy diferente cuando almacena secuencias de valores en lugar de valores individuales. Cada nivel representa un incremento en la altura del √°rbol.
%'¬øcu√°l es el valor del punto I de la lista de entrada'. Esto es diferente a un √°rbol binario que compara el valor buscado √∫nico a cada nodo.


Durante este trabajo mostraremos que nuestro modelo de predicci√≥n usa un \emph{Trie}, para representar un diccionario, en los cuales podemos se√±alar las siguientes operaciones disponibles:

	\begin{itemize}	
		\item \textbf{findByPrefix(x) :}  Retornar una una lista de todos los nodos hasta llegar a un nodo que posea un \emph{String} de par√°metro equivalente a $x$.
		
		\item \textbf{contains(x) :} Retornar una lista de nodos intermedios hasta que el contenido del nodo final sea hoja o el intermedio corresponda a valor de la secuencia \emph{String} $x$.
		
		\item \textbf{remove(x) :} Retorna \emph{true} √≥ \emph{false} cuando es posible remover el nodo con el contenido equivalente a $x$.
		
		\item \textbf{pathTo(x) :} Retorna una lista de nodos hasta llegar a un nodo que posea el contenido equivalente del valor $x$.
	\end{itemize}







\subsection{Alfabeto}

Un alfabeto discreto lo representaremos por $\Sigma$ y una de las caracter√≠sticas b√°sica de este alfabeto es consiste en s√≠mbolos $\sigma$ que pertenecen a $\Sigma$, durante el resto de nuestra investigaci√≥n usaremos solo un $\Sigma = \sigma_{i},\sigma_{i+1}\ =\ 17\  \mbox{s√≠mbolos}$.



Dado un volumen de datos experimental, nuestro alfabeto es mostrado simb√≥licamente como la representaci√≥n de varios nodos contenido en un \emph{Trie} que modela la navegaci√≥n de usuarios para un sitio web.

%Donde $\sigma_{1}$, puede ser definido como la p√°gina inicial de una cierta secuencia  o sesi√≥n de usuario. Este alfabeto es finito y acotado por una miner√≠a de datos ya realizada por \cite{Claude2014} en \emph{Efficient Indexing and Representation of Web Access Logs}. % Referencia al trabajo de claud

%Let A be a discrete alphabet consisting of M  2 symbols; x = x ; : : : ; x ; x 2 A
% be rst n symbols of message; jj be the length of sequence  or the cardinality of
% set . The probability of symbol x = a 2 A for a source with memory depends on
% current context s = x ; : : : ; x 2 A ; d  D. The set of all possible contexts can
% be presented as nodes in M -ary tree with depth D. Context (sequence) s describes a
% path from tree root to the current node also denoted as s.
% Usually the true conditional probabilities are unknown and the coding conditional
% pr ob abilitiesq(ajs) depend on characteristics of one or sev eralsubsequences x (s),
% x (s) is the subsequence of all symbols x such that x ; : : : ; x
% = s . These
% characteristics are: frequency f (ajs) = f (ajx (s)) of symbol a in x (s), alphabet
% A(s) = A(s; x (s)) = fa : f (ajs) > 0g, its cardinality m(s) = jA(s)j etc. Even at
% small D, the n umber of model states is big, subsequences x (s) are short ina verage,
% and their statistics is insu√Ücient for eective compression.
% PPM algorithm [2] is based on an (implicit) assumption: the longer is the common initial part of contexts, the more (in average)similarity there is between their
% conditional probability distributions. High PPM e√Üciency means this assumption is
% fair forthe majority of real sources.



\subsection{Secuencias discretas}

Definimos una secuencia de accesos discreta y finita, dado los accesos que tiene un usuario frente a una web, lo anterior es acotado por el concepto de sesi√≥n, el cual es desde que se inicia la navegaci√≥n por parte de un usuario, es decir secuencia de tama√±o $Seq\ \leq 1$ y de tama√±o no superior a un alfabeto $\Sigma$.



% Compresor tonto o Machine Learning lento para predecir
\subsection{Lossless Data Compression (LDC)}

La compresi√≥n sin p√©rdida o \emph{LDC}, es el arte de poder comprimir \emph{bits} y poder hacer el proceso inverso, es decir poder codificar y decodificar. En cap√≠tulos posteriores se detallar√° m√°s sobre el tema compresi√≥n y como esta √°rea ayuda a crear un modelo de predicci√≥n.





\subsection{Motor de Predicci√≥n}

Es la parte fundamental de un sistema dirigida a adivinar el futuro acceso de un usuario. La salida del motor de predicci√≥n es la siguiente p√°gina, que se compone de un s√≠mbolo representando la direcci√≥n \emph{url} o una secci√≥n en particular de una cierta web. 
% que son propensos a ser solicitado por el usuario en las solicitudes posteriores.

 


\subsection{Resilient Distributed Datasets }

	Los RDD, permiten que en un servidor de Machine Learning pueda mantener un modelo o motor de aprendizaje persistente sin importar en el flujo que se encuentre.

	Esta estructura es fundamental dentro de la librer√≠a que se introducir√° mas adelante, Apache Spark. Esta estructura es una colecci√≥n distribuida de objetos inmutables, cada 
	set de datos en un RDD es divido en particiones l√≥gicas, las cuales puedes ser computadas en distintos Clusters. Los RDD pueden contener cualquier tipo de objeto de los siguientes lenguajes: Python, Scala y Java, incluyendo clases definidas por el usuario. 

	Formalmente los RDD son solo de lectura, una colecci√≥n de objetos divididos. Estos pueden ser creados a trav√©s de  operaciones deterministas en una cierta tabla o un almacenamiento externo u otra RDD.
	Otra de las caracter√≠sticas de los RDD, es que son colecciones de elementos tolerantes a fallas que pueden ser operadas en si mismas o en paralelo.
	Apache Spark hace el uso del concepto de RDD para lograr rapidez y eficiencia en las operaciones de MapReduce, de ser requeridas. Destacamos la escabilidad de esta librer√≠a para un gran nivel de c√≥mputo, pero en este trabajo no se explicar√° el uso de Spark, pero si se utilizar√°n algunos conceptos como RDD y otros.




\subsection{Data Source y Dataset }

	Los \emph{Data Source} son distintas fuentes de datos que podemos ir sacando set de datos (\emph{Dataset}). Ambos conceptos est√°n enfocados a proveer informaci√≥n tanto para el servidor de \emph{Machine Learning}, como para el procesamiento y an√°lisis.
	En este trabajo el dataset con que realizaremos nuestro estudio son los registros de accesos de la web espa√±ola \emph{MSNBC}\cite{Claude2014}, los cuales representan aproximadamente 1.000.000 de registros de accesos.

	Nuestro set de  datos esta basado en los registros (webaccess log), ya previamente depurados con una representaci√≥n num√©rica desde 0 hasta 16, el cual como antes ya se ha se√±alado estar√° relacionado al concepto de alfabeto. Tambi√©n crearemos \emph{dataset} sint√©ticos para poder realizar depuraciones de nuestra implementaci√≥n y casos de bordes.
	
	 



 



% \subsection{DataFrame}


	% A DataFrame is a distributed collection of data, which is organized into named columns. Conceptually, it is equivalent to relational tables with good optimization techniques.
	% Here is a set of few characteristic features of DataFrame ‚àí
	% Ability to process the data in the size of Kilobytes to Petabytes on a single node cluster to large cluster.
	% Supports different data formats (Avro, csv, elastic search, and Cassandra) and storage systems (HDFS, HIVE tables, mysql, etc).
	% State of art optimization and code generation through the Spark SQL Catalyst optimizer (tree transformation framework).
	% Can be easily integrated with all Big Data tools and frameworks via Spark-Core.
	% Provides API for Python, Java, Scala, and R Programming.



% easy text
% https://es.wikipedia.org/wiki/Trie
%Definici√≥n interpretada de esot

%\subsection{Cadenas de Markov}





\subsection{Transferencia de Estado Representacional}

Es un estilo de desarrollo de software para sistemas distribuidos mediante Internet. El uso de REST, de sus siglas en ingles, ha sido adoptado mucho m√°s adoptado que  \emph{Simple Object Access Protocol}, ya que los servicios \emph{REST} aprovechan mayor cantidad el ancho de banda, lo que hace que sea una mejor opci√≥n para su uso a trav√©s de Internet, los mensajes tanto originados por el servidor o cliente puede ser enviados en formato \emph{xml} o \emph{json}. 



%@TODO:
% Este tema deber√≠a detallarse en las siguientes secciones
\section{Trabajos relacionados}

En la literatura, el tema de la predicci√≥n en la web se ha presentado como un tema recurrente provocando bastante atenci√≥n durante los √∫ltimo a√±os y ha sido tratado por 
varios autores. Tenemos los siguientes trabajos de inter√©s:


\input{related-work}


