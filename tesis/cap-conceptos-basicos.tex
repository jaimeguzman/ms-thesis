\chapter[Conceptos B√°sicos]{Conceptos B√°sicos}
\label{ch:Conceptos-Basicos}





En este capitulo se introducira los conceptos principales que se trabajar√°n en los siguientes capitulos:




\subsection{Access Log}

Son los registros que se almacenan en un servidor, los cuales dependiendo de sistema operativo pueden tener mayor o menor informaci√≥n. Cuando los usuarios acceden a los sitios web, estos  suelen dejar una gran cantidad de informaci√≥n de acceso, la cual si es extra√≠da razonable puede ayudar a los administradores de sitio web para obtener acceso a los patrones de los usuarios. 


\subsection{√Årboles Trie}

%%%%% Gueniche_Fournier-Viger_Raman_Tseng
%Tree is a type of prefix tree (aka trie). It contains all training sequences. Each tree node represents an item and each training sequence is represented by a path starting from the tree root and ending by an inner node or a leaf. Just like a prefix tree, the prediction tree is a compact representation of the training sequences. Sequences sharing a common prefix share a common path in the tree. The Lookup Table is an associative array which allows to locate any training sequences in the prediction tree with a constant access time. Finally the Inverted Index is a set of bit vectors that indicates for each item i from the alphabet Z, the set of sequences containing i.


Son estructuras de datos de tipo de √°rbol que almacenan datos en nodos y es de muy f√°cil la recuperaci√≥n de informaci√≥n de estos mismos. Se caracterizan por ser un conjunto de llaves que se representan en el √°rbol y sus nodos internos representan la informaci√≥n, en nuestro caso una car√°cter o string de largo 1. 

Un √°rbol es una estructura general de nodos recursivos. Hay muchos tipos de √°rboles. Los populares son √°rbol binario y el √°rbol de equilibrado. Un Trie es una especie de √°rbol, conocido por muchos nombres incluyendo √°rbol prefijo, √°rbol de b√∫squeda digital, √°rbol de la recuperaci√≥n (de ah√≠ el nombre de ''trie'').

Cada especie de √°rbol tiene distinta finalidad, estructura y comportamiento. Por ejemplo, un √°rbol binario almacena una colecci√≥n de elementos comparables (por ejemplo, n√∫meros). Por lo tanto, se puede utilizar para almacenar un conjunto de n√∫meros, o al √≠ndice de otros datos que pueden ser representados por los n√∫meros (por ejemplo, objetos que pueden ser hash). Su estructura est√° ordenada por lo que se puede buscar r√°pidamente para encontrar nodo. Otras estructuras de √°rbol, como un √°rbol balanceado son similares en principio al trie que se implementar√° en la etapa experimental.

Un trie representa una secuencia  estructurada de nodos, la cual puede almacenar secuencias. % (ver el art√≠culo de wiki). 
Es muy diferente en que la almacena secuencias de valores en lugar de valores individuales. Cada nivel representa un incremento en la altura del √°rbol.
%'¬øcu√°l es el valor del punto I de la lista de entrada'. Esto es diferente a un √°rbol binario que compara el valor buscado √∫nico a cada nodo.


Durante este trabajo mostraremos que nuestro modelo de predicci√≥n usa un \emph{Trie}, para representan un diccionario, en los cuales podemos se√±ar la siguientes operaciones disponibles:

	\begin{itemize}
	
		\item \textbf{findByPrefix(x) :}  Retornar una una lista de todos los nodos hasta llegar a un nodo que posea un string de par√°metro equivalente a $x$.
		
		\item \textbf{contains(x) :} Retornar una lista de nodos intermedios hasta que el contenido del nodo final sea hoja o intermedio corresponda a valor de la secuencia string $x$.
		
		\item \textbf{remove(x) :} Retorna \emph{true} √≥ \emph{false} cuando es posible remover el nodo con la contenido equivalente a $x$.
		
		\item \textbf{pathTo(x) :} Retorna una lista de nodos hasta llegar a un nodo que posea de contenido el valor $x$.
		
	
	\end{itemize}







\subsection{Alfabeto}

Un alfabeto discreto lo representaremos por $\Sigma$ y una de las caracter√≠sticas b√°sica de este alfabeto es consiste en s√≠mbolos $\sigma$ que pertenecen a $\Sigma$, durante el resto de nuestra investigaci√≥n usaremos solo un $\Sigma = \sigma_{i},\sigma_{i+1}\ =\ 17 \mbox{s√≠mbolos}$.



Dado un volumen de datos experimental, nuestro alfabeto es representado simb√≥licamente como la representaci√≥n de varios nodos contenido en un \emph{Trie} que modela la navegaci√≥n de usuarios para un sitio web.
Donde $\sigma_{1}$, puede ser definido como la p√°gina inical de una cierta secuencia  √≥ sesi√≥n de usuario. Este alfabeto es finito y acotado por una miner√≠a de datos ya realizada por \cite{Claude2014} en \emph{Efficient Indexing and Representation of Web Access Logs}. % Referencia al trabajo de claud

%Let A be a discrete alphabet consisting of M  2 symbols; x = x ; : : : ; x ; x 2 A
% be rst n symbols of message; jj be the length of sequence  or the cardinality of
% set . The probability of symbol x = a 2 A for a source with memory depends on
% current context s = x ; : : : ; x 2 A ; d  D. The set of all possible contexts can
% be presented as nodes in M -ary tree with depth D. Context (sequence) s describes a
% path from tree root to the current node also denoted as s.
% Usually the true conditional probabilities are unknown and the coding conditional
% pr ob abilitiesq(ajs) depend on characteristics of one or sev eralsubsequences x (s),
% x (s) is the subsequence of all symbols x such that x ; : : : ; x
% = s . These
% characteristics are: frequency f (ajs) = f (ajx (s)) of symbol a in x (s), alphabet
% A(s) = A(s; x (s)) = fa : f (ajs) > 0g, its cardinality m(s) = jA(s)j etc. Even at
% small D, the n umber of model states is big, subsequences x (s) are short ina verage,
% and their statistics is insu√Ücient for eective compression.
% PPM algorithm [2] is based on an (implicit) assumption: the longer is the common initial part of contexts, the more (in average)similarity there is between their
% conditional probability distributions. High PPM e√Üciency means this assumption is
% fair forthe majority of real sources.



\subsection{Secuencias discretas}

Definimos una secuencia de accesos discreta y finita, dado los accesos que tiene un usuario frente a una web, lo anterior es acotado por el concepto de sesi√≥n, el cual es desde que se inicia la navegaci√≥n por parte de un usuario, es decir secuencia de tama√±o $Seq\ \leq 1$ y de tama√±o no superior a un alfabeto $\Sigma$.



% Compresor tonto o Machine Learning lento para predecir
\subsection{Lossless Data Compression(LDC)}

La compresi√≥n sin p√©rdida o LDC, es el arte de poder comprimir bits y poder hacer el proceso inverso, es decir poder codificar y decodificar. En cap√≠tulos posteriores se introducir√° m√°s sobre el tema compresi√≥n y como esta √°rea ayuda a crear un modelo de predicci√≥n.





\subsection{Motor de Predicci√≥n}

Es la parte fundamental de un sistema dirigida a adivinar el futuro acceso de un usuario. La salida del motor de predicci√≥n es la siguiente p√°gina, que se compone de un s√≠mbolo representando la direcci√≥n \emph{url} o una secci√≥n en particular de un cierta web. 
% que son propensos a ser solicitado por el usuario en las solicitudes posteriores.

 


\subsection{Resilient Distributed Datasets }

	Los RDD, permiten que en un servidor de Machine Learning pueda mantener un modelo o motor de aprendizaje persistente sin importan el flujo en que se encuentre.

	Esta estructura es fundamental dentro de la libera que se introducir√° mas adelante, Apache Spark. Esta estructura es una colecci√≥n distribuida de objetos Inmutable, cada 
	set de datos en un RDD es divido en particiones l√≥gicas, las cuales puedes ser computadas en distintos Clusters. Los RDD pueden contener cualquier tipo de objeto de los siguientes lenguajes: Python, Scala y Java, incluyendo clases definidas por el usuario. 

	Formalmente los RDD son solo de lectura, una colecci√≥n de objetos divididos. Estos pueden ser creados a trav√©s de  operaciones deterministas en una cierta tabla o un almacenamiento externo √≥ otra RDD.
	Otra de las caracter√≠sticas de los RDD, es que son colecciones de elementos tolerantes a fallas que puede ser operadas en si mismas o en paralelo.
	Apache Spark hace el uso del concepto de RDD para lograr rapidez y eficiencia en las operaciones de MapReduce, de ser requeridas. Destacamos la escabilidad de esta librer√≠a para un gran nivel de computo, pero en este trabajo no se explicar√° el uso de Spark, pero si se utilizar√°n algunos conceptos como RDD y otros.




\subsection{Data Source y Dataset }

	Ambos conceptos est√°n enfocados a proveer informaci√≥n tanto para el servidor de Machine Learning, como para el procesamiento y an√°lisis.
	En este trabajo los dataset a estudiar son un los registros de accesos de la web espa√±ola Prisa, los cuales representan 1.000.000 de registros correspondientes.

	Nuestro set de  datos esta basado en los registros (webaccess log), ya previamente depurados con una representaci√≥n num√©rica desde 0 hasta 17, el cual como antes ya se ha se√±alado ser√° nuestro alfabeto. 



 



% \subsection{DataFrame}


	% A DataFrame is a distributed collection of data, which is organized into named columns. Conceptually, it is equivalent to relational tables with good optimization techniques.
	% Here is a set of few characteristic features of DataFrame ‚àí
	% Ability to process the data in the size of Kilobytes to Petabytes on a single node cluster to large cluster.
	% Supports different data formats (Avro, csv, elastic search, and Cassandra) and storage systems (HDFS, HIVE tables, mysql, etc).
	% State of art optimization and code generation through the Spark SQL Catalyst optimizer (tree transformation framework).
	% Can be easily integrated with all Big Data tools and frameworks via Spark-Core.
	% Provides API for Python, Java, Scala, and R Programming.



% easy text
% https://es.wikipedia.org/wiki/Trie
%Definici√≥n interpretada de esot

%\subsection{Cadenas de Markov}





%\subsection{Transferencia de Estado Representacional}

% REST es un estilo de arquitectura software para sistemas hipermedia distribuidos como la World Wide Web. El t√©rmino se origin√≥ en el a√±o 2000, en una tesis doctoral sobre la web escrita por Roy Fielding, uno de los principales autores de la especificaci√≥n del protocolo HTTP y ha pasado a ser ampliamente utilizado por la comunidad de 
%@TODO: poner una sucia referencia a wiki o algun paper mas sensato

%@TODO:
% Este tema deber√≠a detallarse en las siguientes secciones
\section{Trabajos Relacionados}

En la literatura, el tema de la predicci√≥n en la web se ha presentado como un tema concurrente tomando bastante atenci√≥n durante los √∫ltimo a√±os y ha sido abarcado por 
varios autores. Tenemos los siguientes trabajos de inter√©s:


\input{related-work}


