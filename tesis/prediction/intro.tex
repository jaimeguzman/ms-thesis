% Referencias
% ~\cite{}
% ~\cite{}



Las Predicciones sobre \webasccesslog es el objetivo final de esta tesis y en este capítulo estudiaremos los fundamentos teóricos para comprender como abordar el problema de la predicción secuencial en la \web, realizadad por un usuario. Recordemos los \webasccesslog que hemos mencionado en el capitulo~\ref{ch1:intro}, estos registros se guardan en un servidor \web. También recordemos de la literatura que este problema esta planteado por \emph{Claude}~\etal\cite{Claude2014}, que mediante estos registros de accesos que ya han sido procesados con técnicas de \texttt{WUM}\footnote{text} o \texttt{WAP}\footnote{text}, podemos realizar predicciones, por ejemplo mejorar significativamente la navegación del usuario o estudiar su comportamiento en la navegación. Este capítulo abordará en mayor detalle, lo que se señalado.
\newline

% Idea: 
% conexión con capítulos anteriores y fundamentar por que se estudiaron.
Anteriormente en el capitulo~\ref{ch:Compresion-Machine-Learning} estudiamos y discutimos dos áreas de interés, la sección~\ref{ch2:sec-machinelearning-seq-data} de \machinelearning y la sección~\ref{ch2:compressdata-predict-seq} de \losslessdatacompression, en la cual ambas buscan un objetivo común e inclusive se han realizados trabajos (ver referencias~\cite{Sculley2006},~\cite{Li2005} y~\cite{Begleiter2004}) que permiten ver como se integran. Acorde a la literatura presentada ambos enfoques buscan realizar predicciones, ya se ha señalado y fundamentado los puntos a favor que tienen realizar predicciones mediante \machinelearning, básicamente es un algoritmo que realiza un entrenamiento de un conjunto de datos y mediante varias etapas se logra tener un modelo predictivo, es decir, un modelo que generaliza una entrada para lograr una predicción. Los problemas de esta área son la eficiencia y la cantidad de recursos que se utilizan tienden a ser grandes, también los conjuntos de datos de entrenamiento tienen que ser lo más bastos posibles, para reducir errores. Por otro lado, \losslessdatacompression busca especialmente, basado en la literatura que hemos estudiado, predecir sobre secuencias discretas en la que nos hemos aproximado a usar ciertas propiedades de los trabajos realizados por los algoritmos de compresión desarrollados por \lempelziv~\cite{ZivLempel1978}. Dentro del área de las ciencias de la computación, \emph{predecir} es uno de los últimos tópicos en el camino de la realización de análisis de datos predictivos.

% Explicar que es la predicción
El proceso natural de decidir ciertas acciones frecuentes que realizamos es parte de un comportamiento, que se puede analizar y estudiar. Este presenta etapas de recolección de datos  y análisis, que son requeridas para comprender un resultado, sea correcto o no. Este desafío de anticipar la decisión de un evento, es el desarrollo de un análisis predictivos, que veremos durante este capítulo como abordarlo. Evidentemente realizar análisis predictivos es un área bastante compleja que involucra tópicos estadísticos y temas específicos de probabilidades, inclusive los bien conocidos procesos de Markov, con eventos estocásticos. Afirmar con un gran porcentaje de certeza lo que ocurrirá en un futuro escenario y en ciertas condiciones, es \emph{predecir}. Existen variados campos en el cual se pueden realizar predicciones, nosotros buscamos estudiar y comprender los escenarios en que los eventos ocurren de manera discreta y secuencial. 
\newline

Aprender de la experiencia para predecir secuencias de símbolos es un problema fundamental en \machinelearning con varias aplicaciones~\cite{Laird1994}. Probablemente los enfoques que usan \losslessdatacompression son lo más simples de implementar por las predicciones de secuencias discretas, por ejemplo con métodos basados en diccionarios que actualizan constantemente el modelo. También hay aproximaciones de Markov, que durante este capitulo recordaremos de la sección~\ref{sec-clas-alg-compreessdata} y también de los \HMM de la sección~\ref{ch2:sec-hmm}. La estructura de este capítulo cubre los siguientes temas:
% Detallar que veremos en este capitulo
\begin{itemize}
	\menorEspacioItemize
	\item Escenario de predicciones discretas sobre un alfabeto finito.
	\item Representación de datos para un modelo predictivo.
	\item Como evaluar nuestro modelo predictivo.
	\item Herramientas de \machinelearning y \losslessdatacompression para predecir.
\end{itemize}



% TODO:
% Concluir y conectar con el que sigue

\textbf{CONECTOR pendiente a la siguiente subseccion}