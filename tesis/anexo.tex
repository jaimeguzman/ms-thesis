\chapter{Anexos técnicos}
\label{ch:anexo-a}


\section{Uso de linea de Comando Prediction.IO}


La interación con \emph{PIO} es a través de una interface de linea de comando, esta sigue el siguiente formato de uso:

 

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
  pio <command> [options] <args>...
\end{lstlisting}



En caso de tener duda usted al igual que los comandos de bash puede ejecutar

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
pio help <command> 
\end{lstlisting}, para ver mas detalles de cada detalle de los comandos disponibles.


Los comandos de PredictionIO se pueden separar en tres categorías:

\begin{itemize}
	\item \textbf{help} Muestra un resumen del uso  \emph{pio help <command>} para leer sobre un sub comando
	
	\item \textbf{Version} Muestra la version instalada de PredictionIO
	
	
	\item \textbf{Status} Muesta la ruta de instalación y el estatus de ejecución de sistema, como también sus dependencias
	
\end{itemize}

Comandos del servidor de eventos



\begin{itemize}
	\item \textbf{app} Muestra un resumen del uso  \emph{pio help <command>} para leer sobre un sub comando
	
	\item \textbf{Version} Muestra la version instalada de PredictionIO
	
	
	\item \textbf{app }  Administra todas las aplicaciones que usa el servidor de eventos
	\item \textbf{pio app data-delete <name> } Borra toda la data contenida por una aplicación específica
	\item \textbf{pio app delete <name> }  Borra una aplicación completa
	\item \textbf{eventserver }  Lanza el servidor de eventos
	\item \textbf{ --ip <value> } Une la IP seleccionada, el valor por defecto es \emph{localhost}
	\item \textbf{access\_key} Administra todas las llaves de acceso al servidor de eventos ó app
	
\end{itemize}


\section {Comandos del Motor de Predicción}

Es requerido que estos comandos se ejecuten desde la misma carpeta que contiene el proyecto ó aplicación desplegada.

Las opciones  --debug y --verbose  muestran información detallada sobre los conectoes de las aplicaciones complementarias a las que esta compuesta PredictionIO

\begin{itemize}
	\item \textbf{build} Construye y compila el proyecto completo desde la carpeta fuente, tiene un flag adicional \emph{-- clean}, para una compilación limpia.

	\item \textbf{train} Ejecuta el entrenamiento declarado en el motor 

	\item \textbf{deploy} Despliega el motor para ser usado meiante REST como Algoritmo como Servicio. Si no existe ninguna nueva instancia  desplegada, por defecto usará la última creada.
	
\end{itemize}


\newpage
\section{Configuraciones para hacer correr IntelliJ con Apache SPARK y Prediction.IO 0.94}

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
Main class: io.prediction.workflow.CreateWorkflow

VM options: -Dspark.master=local -Dlog4j.configuration=file:/Users/jguzman/PredictionIO/conf/log4j.properties


Program arguments: --engine-id dummy --engine-version dummy --engine-variant engine.json


io.prediction.workflow.CreateWorkflow
-Dspark.master=local -Dlog4j.configuration=file:/Users/jguzman/PredictionIO/conf/log4j.properties -Dorg.xerial.snappy.lib.name=libsnappyjava.jnilib 
--engine-id dummy --engine-version dummy --engine-variant engine.json



SPARK_HOME=/Users/jguzman/PredictionIO/vendors/spark-1.4.1/bin
PIO_FS_BASEDIR=/Users/jguzman/.pio_store
PIO_FS_ENGINESDIR=/Users/jguzman/.pio_store/engines
PIO_FS_TMPDIR=/Users/jguzman/.pio_store/tmp
PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta
PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH
PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model
PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS
PIO_STORAGE_REPOSITORIES_APPDATA_NAME=pio_appdata
PIO_STORAGE_REPOSITORIES_APPDATA_SOURCE=ELASTICSEARCH
PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event
PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE
PIO_STORAGE_SOURCES_ELASTICSEARCH_TYPE=elasticsearch
PIO_STORAGE_SOURCES_ELASTICSEARCH_HOSTS=localhost
PIO_STORAGE_SOURCES_ELASTICSEARCH_PORTS=9300
PIO_STORAGE_SOURCES_LOCALFS_TYPE=localfs
PIO_STORAGE_SOURCES_LOCALFS_HOSTS=/Users/jguzman/.pio_store/models
PIO_STORAGE_SOURCES_LOCALFS_PORTS=0
PIO_STORAGE_SOURCES_HBASE_TYPE=hbase
PIO_STORAGE_SOURCES_HBASE_HOSTS=0
PIO_STORAGE_SOURCES_HBASE_PORTS=0


Main class: io.prediction.workflow.CreateServer
Program Arguments: --engineInstanceId **replace_with_the_id_from_pio_train**




Try -- for more information.
Usage: pio train [--batch <value>] [--skip-sanity-check]
                 [--stop-after-read] [--stop-after-prepare]
                 [--engine-factory <value>] [--engine-params-key <value>]
                 [--scratch-uri <value>]
                 [common options...]

Kick off a training using an engine (variant) to produce an engine instance.
This command will pass all pass-through arguments to its underlying spark-submit
command.

  --batch <value>
      Batch label of the run.
  --skip-sanity-check
      Disable all data sanity check. Useful for speeding up training in
      production.
  --stop-after-read
      Stop the training process after DataSource.read(). Useful for debugging.
  --stop-after-prepare
      Stop the training process after Preparator.prepare(). Useful for
      debugging.
  --engine-factory
      Override engine factory class.
  --engine-params-key
      Retrieve engine parameters programmatically from the engine factory class.
  --scratch-uri
      URI of the working scratch space. Specify this when you want to have all
      necessary files transferred to a remote location. You will usually want to
      specify this when you use --deploy-mode cluster.

\end{lstlisting}

\vspace{1cm}


\section {Llamadas al Servidor de Machine Learning mediante curl }


\begin{lstlisting}

curl -H "Content-Type: application/json"  -d '{"webaccess" : "AC","num" : 10}' http://52.33.180.212:8000/queries.json



\end{lstlisting}



\section{Python SDK para PredictionIO}

Para hacer uso de estos scripts en python es necesario tener instalado el package de prediction para python sdk.

Si se tiene pip instalado correctamente se puede utilizar

\begin{verbatim}
pip install predictionio
\end{verbatim}
ó
\begin{verbatim}
$ easy_install predictionio
\end{verbatim}


Es recomendable tener acceso sudo para evitar problemas con permisos al momento de usar \emph{pip} o \emph{easy\_install} {(ie. sudo pip install predictionio)}.




El siguiente script, permite hacer una sola consulta la cual puede ser ejecutada desde el \emph{cli} de python ó llamando directamente al archivo ejecutable. ( {python test.py})

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
import predictionio

engine_client = predictionio.EngineClient(url="http://localhost:8000")

print engine_client.send_query({"webaccess": "A", "num": 10})
\end{lstlisting}



\newpage
A diferencia del script explicado anteriomente este permite enviar secuencias desde la terminal \emph{cli}, la cual puede seguir en ejecución hasta que el usuario finalice el proceso.

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
"""
Send sample query to prediction engine
"""

import predictionio
import readline

engine_client = predictionio.EngineClient(url="http://localhost:8000")
while True:
    word = raw_input('Enter a Sequences or a single page to predict the next user webaccess: \n')
    print engine_client.send_query({"webaccess": word, "num": 10})

\end{lstlisting}





\section{Programa C++ para hacer splits dentro del Dataset}
Programa para poder pasar la data de msnbc a una representación de símbolos.

\begin{lstlisting}[frame=single,basicstyle=\ttfamily\tiny,]
#include <iostream>     // cout
#include <fstream>      // ifstream
#include <sstream>
#include <algorithm>
#include <string>
#include <cmath>
#include <cstdio>
#include <vector>
#include <map>
#include <iterator>

using namespace std;

/** 
  alias lseq = g++ -std=c++11 letterSequences.cpp -o letterSequences 
  ./letterSequences

% Different categories found in input file:

frontpage news tech local opinion on-air misc weather msn-news health living business msn-sports sports summary bbs travel
**/

 
int main()
{
   map<string, int> mapCategories;

  
   // Inserting data in map
  mapCategories.insert(make_pair("frontpage", 1));
    mapCategories.insert(make_pair("news",    2));
    mapCategories.insert(make_pair("tech",    3));
    mapCategories.insert(make_pair("local",   4));
    mapCategories.insert(make_pair("opinion",   5));
    mapCategories.insert(make_pair("on-air",  6));
    mapCategories.insert(make_pair("misc",    7));
    mapCategories.insert(make_pair("weather",   8));
    mapCategories.insert(make_pair("msn-news",  9));
    mapCategories.insert(make_pair("health",  10));
    mapCategories.insert(make_pair("living",  11));
    mapCategories.insert(make_pair("business",  12));
    mapCategories.insert(make_pair("msn-sports",13));
    mapCategories.insert(make_pair("sports",  14));
    mapCategories.insert(make_pair("summary",   15));
    mapCategories.insert(make_pair("bbs",     16));
    mapCategories.insert(make_pair("travel",  17));
    

   vector<char> alphabet = { 'A','B','C','D','E','F','G',
                'H','I','J','K','L','M','N','O',
                'P','Q','R','S','T','U','V','W',
                'X','Y','Z'};

   // Iterate through all elements in map
   map<string, int>::iterator it = mapCategories.begin();

   ifstream  fin("msnbc990928.seq");
   string    file_line;
   int fold = 0 ;

   while(getline(fin, file_line)){

    string    buf; // Have a buffer string
    stringstream  ss(file_line); // Insert the string into a stream
    vector<string> tokens; // Create vector to hold our words
    
    while (ss >> buf) tokens.push_back(buf);

    if( tokens.size() < 6 ){
      ++fold;
      for (int i = 0; i < tokens.size(); ++i){
        string tmp = tokens.at(i); 
        cout << alphabet.at( stoi(tmp) - 1) << " ";
      }cout<< endl;

    }

    //this value is for make the size of the folds of data
    if( fold == 1000000 ) break;

   }
    return 0;
}
\end{lstlisting}










