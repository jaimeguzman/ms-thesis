

\section{Predicción }

  	
  En esta sección se presenta formalmente la librería y framework Prediction.IO, %@TODO: colocar referencia web
  es un servidor de Machine Learning Open Source para Cientistas de Datos y Desarrolladores que permite
  crear motores de predicción para ambientes de producción, con un bajo tiempo de entrenamiento y despliegue en ambientes productivos. Principalmente esta construido en Apache Spark, HBase y Spray.

  Como ya se ha señalado este ambiente de trabajo se encuentra en un maduración completa que permite tanto disponer
  servidores con motores predictivos, como también toda una infraestructura distribuida para hacer que complejos algorimtos sean utilizados para solucionar problemas reales.





% Si ... osea ya tengo un container en dockers corriendo con prediction.io,
% he estado aprendiendo scala, y retomando un poco java para ver su SDK.

% PIO, tiene practicamente todo armadao, ello no hicieron nada nuevo ... solo juntaron  todo...
% MLIB,SPARK, HBASE,SPRAY hadoop etc...

% bueno el tema es que ellos aun no tienen la posibilidad de poner algoritmos custom, he ahi porque trabajar en scala, 
% por lo que he leido es bien similar a java y mas funcional como lenguaje.


% Ellos ocuapan algo que se llama DASE: https://docs.prediction.io/customize/

% [D] Data Source and Data Preparator
% [A] Algorithm
% [S] Serving
% [E] Evaluation Metrics

% He estado investigando y revisando documentación, Yelp, Skype, Hubot de github y otras implementaciones tienen usando prediction.io


% Ahora todo esto esta usando ML, ahora mi enredo es el siguiente: ellos ocupan toda la logica e ML, hacer que eso funcione con un LZ 78, será una propuesta hibrida ?

% La otra opción es meterle a este "DASE" un algoritmo  que mezcle una representación de cadenas de markov mezclado con LZ78. no se en que punto mezclarlo en el diccionario, o la verdad es como hacer el compresor sea "mas inteligente", encontré un papaer que te adjunto en el cual usan lz78 y lzw, esta interesante ya que le hacen un acercamiento mas al tema de de ser un predictor online.


% Ahora entiendo que la cadenas de markov son y se han ocupado para las predicciones, pero no veo la necesidad de ocuparlas mayormente. Adin me inisiste en que le de una vuelta.... pero mi sensación  es que tengo separada las ideas en dos extremos. 
% Ya revise Suffix Tree para predicciones LZ77 y LZW, también PPM y HMM.

% Ahora entiendo lo que me dijsite de espantanamiento, como que en la literatura no hay mezcla directa de estas dos areas, he leido "invitaciones a colaborar", pero como que funcionan a la par.

% El otro tema que estoy un poco asustado son el dataset de prisa, ya que no estoy seguro que el formato me sirva 100% con predicction.IO, al fin y al cabo es como medio loco "entrenar a un compresor para que sea inteligente o no" ????

% Bueno todo eso es lo que queria compartir contigo en el cafe...




  \subsection{Modelamiento de Eventos}

%https://docs.prediction.io/datacollection/eventmodel/

El modelamiento de eventos, es simplemente el hecho de poder llevar un feature  que es del mundo del ML, es en fin una representación de como se debe tener la data de manera RDD par apoder acceder a ella posteriormente 

Un evento lo definiremos como entidad que nos permite dar una representación temporalizada de información la cual será procesada por un motor de predicción. Analizaremos los eventos que un usuarios realiza para poder acceder a una web. Adicionalmente cuando cada usuario ingresa a una web automáticamente este genera un sesión, la cual es desde que que llega hasta que abandona la web.

Como ya se ha mencionado en sección anteriores esta información esta totalmente depurada y entregada por los access log, los cuales a efectos de temporalidad nos interesa conocer la secuencialidad discreta de estos accesos.


%Poner algo mas matematico.
% EVENT API 

% https://docs.prediction.io/datacollection/eventapi/



  El modelamiento que se realizará contempla que el usuario :


    \begin{itemize}
      \item Tipo de Evento: Visitar
      \item Entidad que ejecuta el evento: Usuario
      \item Propiedades:
          \begin{enumerate}
            \item Pagina actual
            \item Pagina siguiente
            \item Cierre de Sesión
          \end{enumerate}
    \end{itemize}



    El interes de tener un modelo totalmente atómico es poder contemplar la información que nos entrega, destacando sus variables y propiedades como restricciones.


    - Persistencia en el modelo


  \subsection{Ventajas }

El crecimiento de este tipo de arquitectura es tanto horizontal como vertical


  Mix in and implement this trait if your model cannot be persisted by PredictionIO automatically. A companion object extending IPersistentModelLoader is required for PredictionIO to load the persisted model automatically during deployment.

Notice that models generated by PAlgorithm cannot be persisted automatically by nature and must implement these traits if model persistence is desired.



Comentar sobre DASE
Data Source
Algortim
Serving
Engine


A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable, partitioned collection of elements that can be operated on in parallel. This class contains the basic operations available on all RDDs, such as map, filter, and persist. In addition, org.apache.spark.rdd.PairRDDFunctions contains operations available only on RDDs of key-value pairs, such as groupByKey and join; org.apache.spark.rdd.DoubleRDDFunctions contains operations available only on RDDs of Doubles; and org.apache.spark.rdd.SequenceFileRDDFunctions contains operations available on RDDs that can be saved as SequenceFiles. All operations are automatically available on any RDD of the right type (e.g. RDD[(Int, Int)] through implicit.

Internally, each RDD is characterized by five main properties:

A list of partitions
A function for computing each split
A list of dependencies on other RDDs
Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)
All of the scheduling and execution in Spark is done based on these methods, allowing each RDD to implement its own way of com