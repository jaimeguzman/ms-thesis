% DEFINIR EL PROBLEMA

\section{Definición del problema}
% IDEA: me gustaria que esta sección  no se llamara DEFINICION DE PROBLEMA, intrinsicamente he hablado que el problema es como mejorar las predicciones secienciales usando lo mejor de dos áreas.



% esto creo que se repite en contexto o intro.
En esta tesis el problema que se busca solucionar es la predicción a páginas web, que se representan mediante símbolos que pertenecen a una determinada secuencia de accesos, la cual representa una sesión. Este problemática esta presente hace años y diversos autores han trabajado con distintos enfoques. 

% TODO: Este parrafo es desastroso
%\emph{Rissanen}\cite{Rissanen1983} y Langdom\cite{Langdon1983} en los laboratorios \emph{Bell}, al realizar pruebas y experimentar con un \emph{robot} que tiraba una moneda compitiendo con una persona, aquel robot realizaba todos los cálculos {markovianos} y las probabilidades condicionales para que cierto evento ocurra, a diferencia del sujeto que sólo estaba esperando un resultado aleatorio, la diferencia se marco en los costos de tiempo y de computo que se realizaron, por un parte la demora del \emph{robot} haciendo sus cálculos no mejoraba a la probabilidad aleatoria con que la persona a que enfrentaba. 


La solución a este problema que pretendemos abordar, es mediante modelos predictivos. Como el lector puede imaginar predecir no es trivial y requiere de una basta cantidad de  información para poder analizar y desarrollar un modelo, que logre idealmente abarcar varios escenarios reales en que un usuario se enfrenta a una \web. Sí podemos llegar a acercarnos y minimizar el error estaremos cerca a predicciones aceptables. Sin embargo, dos áreas han tratado de resolver el problema; \machinelearning y \datacompression. Este último presenta condiciones desfavorables para los algoritmos predictivos que se pueden implementar, es decir, funcionan totalmente desconectados de la fuente de datos de entrada, esto implica que la validez del modelo solo es factible cuando esta realizando predicciones sin usuarios concurrentes o como un modelo desconectado de la fuente, lo que inhabilita rápidamente al modelo y en general no logrará un resultado en demanda. Por otro lado, en el acercamiento que ofrece \machinelearning debemos crear un modelo, tal que  deba entrenar y luego generar una función predictiva a lo cual se le suma un gran cantidad de datos. El proceso anterior puede producir un modelo bastante pesado para poder funcionar como un modelo predictivo \online. 

Para acotar nuestro problema, buscaremos resolver predicciones secuenciales discretas con un modelo generado por un algoritmo de compresión, aplicado a un conjunto de datos generados sintética-mente y otros datos real provistos por \emph{MSNBC}\cite{Claude2014}, un sitio \web de noticias. 

% ESTE TEXTO ESTA HORRIBLE:
% Este modelo propuesto de componentes híbridas, es decir, algoritmos de compresión  y un servidor de \machinelearning, buscaremos la solución a nuestro problema planteado, disponiendo como servicio, es decir crear, manteniendo la  componente \online del modelo predictivo vigente con ayuda de \losslessdatacompression y el famoso algoritmo \texttt{LZ78}; dando una predictibilidad inmediata que hoy en la industria es necesaria para usar los datos recolectados y entregar nuevos enfoques a las decisiones basadas en esta perspectiva predictiva, como también dando un avance en el análisis de datos predictivos. Usando un algoritmo de tipo \LDC reemplazando en el proceso de aprendizaje de una arquitectura de  servicios  \machinelearning podemos alcanzar a una buena solución o a lo menos estar sobre el promedio aleatorio de ocurrencia de eventos.

